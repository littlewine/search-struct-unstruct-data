{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching Unstructured and Structured Data #\n",
    "## Assignment 1: Retrieval models [100 points] ##\n",
    "**TA**: Nikos Voskarides (n.voskarides@uva.nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will get familiar with basic information retrieval concepts. You will implement and evaluate different information retrieval ranking models and evaluate their performance.\n",
    "\n",
    "We provide you with a Indri index. To query the index, you'll use a Python package ([pyndri](https://github.com/cvangysel/pyndri)) that allows easy access to the underlying document statistics.\n",
    "\n",
    "For evaluation you'll use the [TREC Eval](https://github.com/usnistgov/trec_eval) utility, provided by the National Institute of Standards and Technology of the United States. TREC Eval is the de facto standard way to compute Information Retrieval measures and is frequently referenced in scientific papers.\n",
    "\n",
    "This is a **groups-of-three assignment**, the deadline is **Monday, 22/1, at 23:59**. Code quality, informative comments and convincing analysis of the results will be considered when grading. Submission should be done through blackboard, questions can be asked on the course [Piazza](https://piazza.com/class/ixoz63p156g1ts).\n",
    "\n",
    "### Technicalities (must-read!) ###\n",
    "\n",
    "The assignment directory is organized as follows:\n",
    "   * `./assignment.ipynb` (this file): the description of the assignment.\n",
    "   * `./index/`: the index we prepared for you.\n",
    "   * `./ap_88_90/`: directory with ground-truth and evaluation sets:\n",
    "      * `qrel_test`: test query relevance collection (**test set**).\n",
    "      * `qrel_validation`: validation query relevance collection (**validation set**).\n",
    "      * `topics_title`: semicolon-separated file with query identifiers and terms.\n",
    "\n",
    "You will need the following software packages (tested with Python 3.5 inside [Anaconda](https://conda.io/docs/user-guide/install/index.html)):\n",
    "   * Python 3.5 and Jupyter\n",
    "   * Indri + Pyndri (Follow the installation instructions [here](https://github.com/nickvosk/pyndri/blob/master/README.md))\n",
    "   * gensim [link](https://radimrehurek.com/gensim/install.html)\n",
    "   * TREC Eval [link](https://github.com/usnistgov/trec_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import copy\n",
    "import gensim\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "import glob\n",
    "import io\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyndri\n",
    "import pyndri.compat\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from gensim.similarities import WmdSimilarity\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from itertools import combinations\n",
    "from itertools import groupby\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyndri primer ###\n",
    "For this assignment you will use [Pyndri](https://github.com/cvangysel/pyndri) [[1](https://arxiv.org/abs/1701.00749)], a python interface for [Indri](https://www.lemurproject.org/indri.php). We have indexed the document collection and you can query the index using Pyndri. We will start by giving you some examples of what Pyndri can do:\n",
    "\n",
    "First we read the document collection index with Pyndri:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = pyndri.Index('index/')\n",
    "token2id, id2token, _ = index.get_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_run(model_name, data, out_f,\n",
    "              max_objects_per_query=sys.maxsize,\n",
    "              skip_sorting=False):\n",
    "    \"\"\"\n",
    "    Write a run to an output file.\n",
    "    Parameters:\n",
    "        - model_name: identifier of run.\n",
    "        - data: dictionary mapping topic_id to object_assesments;\n",
    "            object_assesments is an iterable (list or tuple) of\n",
    "            (relevance, object_id) pairs.\n",
    "            The object_assesments iterable is sorted by decreasing order.\n",
    "        - out_f: output file stream.\n",
    "        - max_objects_per_query: cut-off for number of objects per query.\n",
    "    \"\"\"\n",
    "    for subject_id, object_assesments in data.items():\n",
    "        if not object_assesments:\n",
    "            logging.warning('Received empty ranking for %s; ignoring.',\n",
    "                            subject_id)\n",
    "\n",
    "            continue\n",
    "\n",
    "        # Probe types, to make sure everything goes alright.\n",
    "        # assert isinstance(object_assesments[0][0], float) or \\\n",
    "        #     isinstance(object_assesments[0][0], np.float32)\n",
    "        assert isinstance(object_assesments[0][1], str) or \\\n",
    "            isinstance(object_assesments[0][1], bytes)\n",
    "\n",
    "        if not skip_sorting:\n",
    "            object_assesments = sorted(object_assesments, reverse=True)\n",
    "\n",
    "        if max_objects_per_query < sys.maxsize:\n",
    "            object_assesments = object_assesments[:max_objects_per_query]\n",
    "\n",
    "        if isinstance(subject_id, bytes):\n",
    "            subject_id = subject_id.decode('utf8')\n",
    "\n",
    "        for rank, (relevance, object_id) in enumerate(object_assesments):\n",
    "            if isinstance(object_id, bytes):\n",
    "                object_id = object_id.decode('utf8')\n",
    "\n",
    "            out_f.write(\n",
    "                '{subject} Q0 {object} {rank} {relevance} '\n",
    "                '{model_name}\\n'.format(\n",
    "                    subject=subject_id,\n",
    "                    object=object_id,\n",
    "                    rank=rank + 1,\n",
    "                    relevance=relevance,\n",
    "                    model_name=model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the query file\n",
    "You can parse the query file (`ap_88_89/topics_title`) using the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parse_topics(file_or_files,\n",
    "                 max_topics=sys.maxsize, delimiter=';'):\n",
    "    assert max_topics >= 0 or max_topics is None\n",
    "\n",
    "    topics = collections.OrderedDict()\n",
    "\n",
    "    if not isinstance(file_or_files, list) and \\\n",
    "            not isinstance(file_or_files, tuple):\n",
    "        if hasattr(file_or_files, '__iter__'):\n",
    "            file_or_files = list(file_or_files)\n",
    "        else:\n",
    "            file_or_files = [file_or_files]\n",
    "\n",
    "    for f in file_or_files:\n",
    "        assert isinstance(f, io.IOBase)\n",
    "\n",
    "        for line in f:\n",
    "            assert(isinstance(line, str))\n",
    "\n",
    "            line = line.strip()\n",
    "\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            topic_id, terms = line.split(delimiter, 1)\n",
    "\n",
    "            if topic_id in topics and (topics[topic_id] != terms):\n",
    "                    logging.error('Duplicate topic \"%s\" (%s vs. %s).',\n",
    "                                  topic_id,\n",
    "                                  topics[topic_id],\n",
    "                                  terms)\n",
    "\n",
    "            topics[topic_id] = terms\n",
    "\n",
    "            if max_topics > 0 and len(topics) >= max_topics:\n",
    "                break\n",
    "\n",
    "    return topics\n",
    "\n",
    "# with open('./ap_88_89/topics_title', 'r') as f_topics:\n",
    "#     print(parse_topics([f_topics]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Implement and compare lexical IR methods [40 points] ### \n",
    "\n",
    "In this task you will implement a number of lexical methods for IR using the **Pyndri** framework. Then you will evaluate these methods on the dataset we have provided using **TREC Eval**.\n",
    "\n",
    "Use the **Pyndri** framework to get statistics of the documents (term frequency, document frequency, collection frequency; **you are not allowed to use the query functionality of Pyndri**) and implement the following scoring methods in **Python**:\n",
    "\n",
    "- [TF-IDF](http://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html). **[5 points]**\n",
    "- [BM25](http://nlp.stanford.edu/IR-book/html/htmledition/okapi-bm25-a-non-binary-model-1.html) with k1=1.2 and b=0.75. **[5 points]**\n",
    "- Language models ([survey](https://drive.google.com/file/d/0B-zklbckv9CHc0c3b245UW90NE0/view))\n",
    "    - Jelinek-Mercer (explore different values of ð›Œ in the range [0.1, 0.5, 0.9]). **[10 points]**\n",
    "    - Dirichlet Prior (explore different values of ð› [500, 1000, 1500]). **[5 points]**\n",
    "    - Absolute discounting (explore different values of ð›… in the range [0.1, 0.5, 0.9]). **[5 points]**\n",
    "    \n",
    "Implement the above methods and report evaluation measures (on the test set) using the hyper parameter values you optimized on the validation set (also report the values of the hyper parameters). Use TREC Eval to obtain the results and report on `NDCG@10`, Mean Average Precision (`MAP@1000`), `Precision@5` and `Recall@1000`.\n",
    "\n",
    "For the language models, create plots showing `NDCG@10` with varying values of the parameters. You can do this by chaining small scripts using shell scripting (preferred) or execute trec_eval using Python's `subprocess`.\n",
    "\n",
    "Compute significance of the results using a [two-tailed paired Student t-test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html) **[10 points]**. Be wary of false rejection of the null hypothesis caused by the [multiple comparisons problem](https://en.wikipedia.org/wiki/Multiple_comparisons_problem). There are multiple ways to mitigate this problem and it is up to you to choose one.\n",
    "\n",
    "Analyse the results by identifying specific queries where different methods succeed or fail and discuss possible reasons that cause these differences. This is *very important* in order to understand how the different retrieval functions behave.\n",
    "\n",
    "**NOTE**: Donâ€™t forget to use log computations in your calculations to avoid underflows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: You should structure your code around the helper functions we provide below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering statistics about 456 terms.\n",
      "Inverted index creation took 37.70044946670532 seconds.\n"
     ]
    }
   ],
   "source": [
    "with open('./ap_88_89/topics_title', 'r') as f_topics:\n",
    "    queries = parse_topics([f_topics])\n",
    "\n",
    "index = pyndri.Index('index/')\n",
    "start_time = time.time()\n",
    "num_documents = index.maximum_document() - index.document_base()\n",
    "\n",
    "dictionary = pyndri.extract_dictionary(index)\n",
    "\n",
    "tokenized_queries = {\n",
    "    query_id: [dictionary.translate_token(token)\n",
    "               for token in index.tokenize(query_string)\n",
    "               if dictionary.has_token(token)]\n",
    "    for query_id, query_string in queries.items()}\n",
    "\n",
    "query_term_ids = set(\n",
    "    query_term_id\n",
    "    for query_term_ids in tokenized_queries.values()\n",
    "    for query_term_id in query_term_ids)\n",
    "\n",
    "print('Gathering statistics about', len(query_term_ids), 'terms.')\n",
    "\n",
    "# inverted index creation.\n",
    "\n",
    "document_lengths = {}\n",
    "unique_terms_per_document = {}\n",
    "\n",
    "inverted_index = collections.defaultdict(dict)\n",
    "collection_frequencies = collections.defaultdict(int)\n",
    "\n",
    "total_terms = 0\n",
    "\n",
    "for int_doc_id in range(index.document_base(), index.maximum_document()):\n",
    "    ext_doc_id, doc_token_ids = index.document(int_doc_id)\n",
    "\n",
    "    document_bow = collections.Counter(\n",
    "        token_id for token_id in doc_token_ids\n",
    "        if token_id > 0)\n",
    "    document_length = sum(document_bow.values())\n",
    "\n",
    "    document_lengths[int_doc_id] = document_length\n",
    "    total_terms += document_length\n",
    "\n",
    "    unique_terms_per_document[int_doc_id] = len(document_bow)\n",
    "\n",
    "    for query_term_id in query_term_ids:\n",
    "        assert query_term_id is not None\n",
    "\n",
    "        document_term_frequency = document_bow.get(query_term_id, 0)\n",
    "\n",
    "        if document_term_frequency == 0:\n",
    "            continue\n",
    "\n",
    "        collection_frequencies[query_term_id] += document_term_frequency\n",
    "        inverted_index[query_term_id][int_doc_id] = document_term_frequency\n",
    "\n",
    "avg_doc_length = total_terms / num_documents\n",
    "\n",
    "print('Inverted index creation took', time.time() - start_time, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_retrieval(model_name, score_fn, **args):\n",
    "    \"\"\"\n",
    "    Runs a retrieval method for all the queries and writes the TREC-friendly results in a file.\n",
    "    \n",
    "    :param model_name: the name of the model (a string)\n",
    "    :param score_fn: the scoring function (a function - see below for an example) \n",
    "    \"\"\"\n",
    "    run_out_path = '{}.run'.format(model_name)\n",
    "\n",
    "    if os.path.exists(run_out_path):\n",
    "        return\n",
    "\n",
    "    retrieval_start_time = time.time()\n",
    "\n",
    "    print('Retrieving using', model_name)\n",
    "\n",
    "    data = {}\n",
    "    \n",
    "    for qid in tokenized_queries.keys(): #for each query\n",
    "#     for qid in ['93']: #test\n",
    "\n",
    "        score = {}\n",
    "            #hack for BM25 (iterate duplicate terms in query once)\n",
    "        try:\n",
    "            if score_fn==bm25:\n",
    "                tokenized_queries[qid] = list(set(tokenized_queries[qid]))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        for query_term_id in tokenized_queries[qid]: #for each word_id in query\n",
    "\n",
    "            for (int_document_id,document_term_freq) in zip(inverted_index[query_term_id].keys(),inverted_index[query_term_id].values()):\n",
    "                    #for each document where the word appears, calculate scoring function increment its score\n",
    "                new_score = score_fn(int_document_id, query_term_id, document_term_freq, **args)\n",
    "                \n",
    "                if int_document_id not in score.keys():\n",
    "                    #print('initiallizing and incrementing score')\n",
    "                    score[int_document_id] = new_score\n",
    "                else:\n",
    "                    #print('incrementing score')\n",
    "                    score[int_document_id] += new_score\n",
    "\n",
    "        #turn dict to list of tuples and continue        \n",
    "        # The dictionary data should have the form: query_id --> (document_score, external_doc_id)\n",
    "        data[qid] = [(score, index.ext_document_id(doc_id)) for (score, doc_id) in zip(score.values(), score.keys())]\n",
    "                \n",
    "#     write out\n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name=model_name,\n",
    "            data=data,\n",
    "            out_f=f_out,\n",
    "\n",
    "            max_objects_per_query=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(int_document_id, query_term_id, document_term_freq):\n",
    "    \"\"\"\n",
    "    Scoring function for a document and a query term\n",
    "    \n",
    "    :param int_document_id: the document id\n",
    "    :param query_token_id: the query term id (assuming you have split the query to tokens)\n",
    "    :param document_term_freq: the document term frequency of the query term \n",
    "    \"\"\"\n",
    "    \n",
    "    ## Amount of time a term appears in a document  \n",
    "    df = document_term_freq\n",
    "   \n",
    "    ## Number of documents containing the query word\n",
    "    n = len(inverted_index[query_term_id])\n",
    "    \n",
    "\n",
    "    tf = np.log2(1 + df)\n",
    "\n",
    "    idf = np.log2((n/df))\n",
    "    \n",
    "    score = tf * idf\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "run_retrieval('retrievals/tf-idf',tfidf)\n",
    "\n",
    "print ('elapsed time:',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trec_eval command for evalutaion of tf-idf \n",
    "!trec_eval -m all_trec ./ap_88_89/qrel_validation retrievals/tf-idf.run | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\"\n",
    "\n",
    "# trec_eval command for test of tf-idf \n",
    "!trec_eval -m all_trec ./ap_88_89/qrel_test retrievals/tf-idf.run | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25(int_document_id, query_term_id, document_term_freq ,k1=1.2 , b=0.75,length_avg = np.mean(np.array(list(document_lengths.values())))) :\n",
    "    \"\"\"\n",
    "    Scoring function for a document and a query term\n",
    "    \n",
    "    :param int_document_id: the document id\n",
    "    :param query_token_id: the query term id (assuming you have split the query to tokens)\n",
    "    :param document_term_freq: the document term frequency of the query term\n",
    "    \n",
    "    Hyperparameters: k1=1.2 and b=0.75\n",
    "    -\n",
    "    \"\"\"\n",
    "    \n",
    "    ## Amount of time a term appears in a document  \n",
    "    df = document_term_freq\n",
    "     \n",
    "    \n",
    "    ## tf, idf\n",
    "    tf = np.log2(1 + df)\n",
    "    idf = np.log2((len(inverted_index[query_term_id])/df))\n",
    "    \n",
    "    ## Total terms in a document : document_lengths[int_document_id]    \n",
    "    ## Amount of documents containing a term : len(inverted_index[query_term_id])\n",
    "    ## document length : document_lengths[int_document_id]\n",
    "    \n",
    "    return ((k1+1)*tf*idf)/(k1*((1-b)+b*(document_lengths[int_document_id] /length_avg))+tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time() \n",
    "\n",
    "run_retrieval('retrievals/bm25',bm25)\n",
    "\n",
    "print('BM25 scoring took', time.time() - start_time, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trec_eval command for evalutaion of bm25\n",
    "!trec_eval -m all_trec ./ap_88_89/qrel_validation retrievals/bm25.run | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\"\n",
    "\n",
    "# trec_eval command for test of bm25\n",
    "!trec_eval -m all_trec ./ap_88_89/qrel_test retrievals/bm25.run | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jelinek-Mercer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precompute the 2nd term of jelinek mercer smoothening to speed-up computations\n",
    "P_mle_col = dict()\n",
    "for query_term_id in query_term_ids:\n",
    "    \n",
    "    P_mle_col[query_term_id] = ((index.get_term_frequencies()[query_term_id]) )/index.total_terms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jelinek_mercer(int_document_id, query_term_id, document_term_freq, lambd = 0.8):\n",
    "    \"\"\"\n",
    "    Scoring function for a document and a query term\n",
    "    \n",
    "    :param int_document_id: the document id\n",
    "    :param query_token_id: the query term id (assuming you have split the query to tokens)\n",
    "    :param document_term_freq: the document term frequency of the query term\n",
    "    :param lambd: lambda value of linear interpolation (default = 0.75)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return np.log((1+(1-lambd)/lambd+document_term_freq/(document_lengths[int_document_id]*P_mle_col[query_term_id])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "test_dict = run_retrieval('retrievals/jelinek_mercer',jelinek_mercer)\n",
    "\n",
    "print ('elapsed time:',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# trec_eval command for evalutaion of jelinek_mercer\n",
    "!trec_eval -m all_trec ./ap_88_89/qrel_validation retrievals/jelinek_mercer.run | grep -E \"^ndcg_cut_10\\s|^map\\s|^P_5\\s|^recall_1000\\s\"\n",
    "\n",
    "# trec_eval command for test of jelinek_mercer\n",
    "!trec_eval -m all_trec ./ap_88_89/qrel_test retrievals/jelinek_mercer.run | grep -E \"^ndcg_cut_10\\s|^map\\s|^P_5\\s|^recall_1000\\s\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dirichlet Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precompute the 2nd term of jelinek mercer smoothening to speed-up computations\n",
    "P_mle_col = dict()\n",
    "for query_term_id in query_term_ids:\n",
    "    count = 0 \n",
    "    for int_document_id in inverted_index[query_term_id].keys():\n",
    "        \n",
    "        count +=(inverted_index[query_term_id][int_document_id]/document_lengths[int_document_id])\n",
    "    \n",
    "    \n",
    "    P_mle_col[query_term_id] = count*(1/index.total_terms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dirichlet_prior(int_document_id, query_term_id, document_term_freq,query_length, mu=1400):\n",
    "    \"\"\"\n",
    "    Scoring function for a document and a query term\n",
    "    \n",
    "    :param int_document_id: the document id\n",
    "    :param query_token_id: the query term id (assuming you have split the query to tokens)\n",
    "    :param document_term_freq: the document term frequency of the query term \n",
    "    \"\"\"\n",
    "   \n",
    "    ##p_w_C --------------> P_mle_col[query_term_id])\n",
    "    ## document length --------------> document_lengths[int_document_id]\n",
    "    #l --------------> document_lengths[int_document_id]\n",
    "    \n",
    "   \n",
    "    return np.log(1+(document_term_freq/(mu*P_mle_col[query_term_id])))\\\n",
    "                                    +query_length*np.log(mu/(mu+document_lengths[int_document_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "test_dict = run_retrieval('retrievals/dirichlet_prior',dirichlet_prior)\n",
    "\n",
    "print ('elapsed time:',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #trec_eval command for evalutaion of dirichlet_prior\n",
    "!trec_eval -m all_trec ./ap_88_89/qrel_validation retrievals/dirichlet_prior.run | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\"\n",
    "\n",
    "\n",
    "# #trec_eval command for test of dirichlet_prior\n",
    "!trec_eval -m all_trec ./ap_88_89/qrel_test retrievals/dirichlet_prior.run | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute discounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_discounting(int_document_id, query_term_id, document_term_freq,query_length, delta=0.9):\n",
    "    \"\"\"\n",
    "    Scoring function for a document and a query term\n",
    "    \n",
    "    :param int_document_id: the document id\n",
    "    :param query_token_id: the query term id (assuming you have split the query to tokens)\n",
    "    :param document_term_freq: the document term frequency of the query term \n",
    "    \"\"\"\n",
    "\n",
    "    ## p_w_C = P_mle_col[query_term_id])\n",
    "    ## document length : document_lengths[int_document_id]\n",
    "    ## document length u: collection_frequencies[query_term_id]\n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "    return np.log(np.max(document_term_freq-delta,0)/ \\\n",
    "                (delta*unique_terms_per_document[int_document_id]*P_mle_col[query_term_id]))\\\n",
    "                +query_length*np.log((delta*unique_terms_per_document[int_document_id])/delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "test_dict = run_retrieval('retrievals/absolute_discounting', absolute_discounting)\n",
    "\n",
    "print ('elapsed time:',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trec_eval command for evalutaion of absolute\n",
    "!trec_eval -m all_trec ./ap_88_89/qrel_validation retrievals/absolute_discounting.run | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\"\n",
    "\n",
    "# trec_eval command for test of absolute\n",
    "!trec_eval -m all_trec ./ap_88_89/qrel_test retrievals/absolute_discounting.run | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter testingÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(filenames, validation=False):\n",
    "    \"\"\"\n",
    "    Function to get scores from trec_eval using a \n",
    "    :param filenames: a list of *.run files (retrieval scores for queries)\n",
    "    :param validation: boolean. Perform evaluation on validation or test set (queries)\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    for filename in filenames:\n",
    "        param_value = float(filename.split(\"=\")[-1].split('.run')[0])\n",
    "        if validation:\n",
    "            result = !trec_eval -m all_trec ./ap_88_89/qrel_validation {filename} | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\"\n",
    "        else:\n",
    "            result = !trec_eval -m all_trec ./ap_88_89/qrel_test {filename} | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\"\n",
    "\n",
    "        for row in result:\n",
    "            metric = row.split(' ')[0]\n",
    "            score = float(row.split('\\t')[-1])\n",
    "            if metric not in scores.keys():\n",
    "                scores[metric] = {}\n",
    "            scores[metric][param_value] = score\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hyperparameters(hyperparameters,funct_name,score_function):\n",
    "    \n",
    "    for param_value in hyperparameters:\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        filename = 'retrievals/'+funct_name+'='+str(param_value)\n",
    "        \n",
    "        if funct_name== 'jelinek_mercer_lambda':\n",
    "            run_retrieval(filename,score_function, lambd = param_value)\n",
    "        elif funct_name=='dirichlet_prior_mu':\n",
    "            run_retrieval(filename,dirichlet_prior, mu = param_value)\n",
    "        \n",
    "        elif funct_name=='absolute_discounting_delta':\n",
    "            run_retrieval(filename,absolute_discounting, delta = param_value)\n",
    "            \n",
    "        else:\n",
    "            print (\"Wrong method name\")\n",
    "            return\n",
    "            \n",
    "\n",
    "        print ('finished {} in {} sec'.format(filename,(time.time()-start_time)))\n",
    "    \n",
    "    filenames = glob.glob('./retrievals/'+funct_name+'=*')\n",
    "    scores = get_scores(filenames)\n",
    "    scores = pd.DataFrame.from_dict(scores,dtype=float)\n",
    "    scores.index.name = 'delta'\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_jm = test_hyperparameters(np.arange(0.1,0.91,0.1),'jelinek_mercer_lambda',jelinek_mercer)\n",
    "scores_jm.drop('recall_1000',axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dirich = test_hyperparameters(np.arange(500,1501, 100),'dirichlet_prior_mu',dirichlet_prior)\n",
    "scores_dirich.drop('recall_1000',axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_abs_disc = test_hyperparameters(np.arange(0.1,0.91, 0.1),'absolute_discounting_delta',absolute_discounting)\n",
    "scores_abs_disc.drop('recall_1000',axis=1).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg_all={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "ndcg = pd.DataFrame(columns=columns)\n",
    "\n",
    "for param_value in columns:\n",
    "    start_time = time.time()\n",
    "\n",
    "    filename = 'retrievals/jelinek_mercer_lambda='+str(param_value)\n",
    "\n",
    "    run_retrieval(filename,jelinek_mercer, lambd = param_value)\n",
    "\n",
    "    print ('finished {} in {} sec'.format(filename,(time.time()-start_time)))\n",
    "\n",
    "    results = !trec_eval -m all_trec -q ./ap_88_89/qrel_test { filename }.run | grep -E \"^ndcg_cut_10\\s\"\n",
    "\n",
    "    for result in results:\n",
    "        result = re.sub( '\\s+', ' ', result ).strip().split()\n",
    "\n",
    "        idx = result[1]\n",
    "        value = result[2]\n",
    "        param_value = round(param_value,1)\n",
    "\n",
    "        ndcg.set_value(idx, param_value, value)\n",
    "        \n",
    "ndcg_all['jelinek_mercer'] = ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "ndcg = pd.DataFrame(columns=columns)\n",
    "\n",
    "for param_value in columns:\n",
    "    start_time = time.time()\n",
    "\n",
    "    filename = 'retrievals/absolute_discounting_delta='+str(param_value)\n",
    "\n",
    "    run_retrieval(filename,jelinek_mercer, lambd = param_value)\n",
    "\n",
    "    print ('finished {} in {} sec'.format(filename,(time.time()-start_time)))\n",
    "\n",
    "    results = !trec_eval -m all_trec -q ./ap_88_89/qrel_test { filename }.run | grep -E \"^ndcg_cut_10\\s\"\n",
    "\n",
    "    for result in results:\n",
    "        result = re.sub( '\\s+', ' ', result ).strip().split()\n",
    "\n",
    "        idx = result[1]\n",
    "        value = result[2]\n",
    "        param_value = round(param_value,1)\n",
    "\n",
    "        ndcg.set_value(idx, param_value, value)\n",
    "\n",
    "ndcg_all['absolute_discounting'] = ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = np.arange(500,1501,100)\n",
    "\n",
    "ndcg = pd.DataFrame(columns=columns)\n",
    "\n",
    "for param_value in columns:\n",
    "    start_time = time.time()\n",
    "\n",
    "    filename = 'retrievals/dirichlet_prior_mu='+str(param_value)\n",
    "\n",
    "    run_retrieval(filename,jelinek_mercer, lambd = param_value)\n",
    "\n",
    "    print ('finished {} in {} sec'.format(filename,(time.time()-start_time)))\n",
    "\n",
    "    results = !trec_eval -m all_trec -q ./ap_88_89/qrel_test { filename }.run | grep -E \"^ndcg_cut_10\\s\"\n",
    "\n",
    "    for result in results:\n",
    "        result = re.sub( '\\s+', ' ', result ).strip().split()\n",
    "\n",
    "        idx = result[1]\n",
    "        value = result[2]\n",
    "        param_value = round(param_value,1)\n",
    "\n",
    "        ndcg.set_value(idx, param_value, value)\n",
    "\n",
    "ndcg_all['dirichlet_prior'] = ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_results = pd.DataFrame()\n",
    "\n",
    "results = !trec_eval -m all_trec -q ./ap_88_89/qrel_test retrievals/tf-idf.run | grep -E \"^ndcg_cut_10\\s\"\n",
    "\n",
    "for result in results:\n",
    "    result = re.sub( '\\s+', ' ', result ).strip().split()\n",
    "\n",
    "    index = result[1]\n",
    "    value = float(result[2])\n",
    "\n",
    "    tfidf_results.set_value(index, 1, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_results = pd.DataFrame()\n",
    "\n",
    "results = !trec_eval -m all_trec -q ./ap_88_89/qrel_test retrievals/bm25.run | grep -E \"^ndcg_cut_10\\s\"\n",
    "\n",
    "for result in results:\n",
    "    result = re.sub( '\\s+', ' ', result ).strip().split()\n",
    "\n",
    "    index = result[1]\n",
    "    value = float(result[2])\n",
    "\n",
    "    bm25_results.set_value(index, 1, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores = pd.DataFrame()\n",
    "best_scores['absolute_discounting'] = ndcg_all['absolute_discounting'][0.1]\n",
    "best_scores['jelinek_mercer'] = ndcg_all['jelinek_mercer'][0.1]\n",
    "best_scores['dirichlet_prior'] = ndcg_all['dirichlet_prior'][1500]\n",
    "\n",
    "best_scores['tf-idf'] = tfidf_results\n",
    "best_scores['BM25'] = bm25_results\n",
    "\n",
    "\n",
    "best_scores = best_scores.applymap(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot non-zero queries only\n",
    "best_scores[best_scores.sum(axis=1)>0].plot(kind='bar',figsize=(18,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test(method1,method2,a=0.05):\n",
    "    \n",
    "    p_value = ttest_rel(method1, method2)[1]\n",
    "    \n",
    "    if p_value>a:\n",
    "        return (p_value, 'not-rejected')\n",
    "    else:\n",
    "        return (p_value, 'rejected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combs = list(combinations(best_scores.columns,2))\n",
    "\n",
    "for pair in combs:\n",
    "    print(pair[0],pair[1])\n",
    "    print(t_test(best_scores[pair[0]],best_scores[pair[1]],a=0.05/len(combs)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Latent Semantic Models (LSMs) [20 points] ###\n",
    "\n",
    "In this task you will experiment with applying distributional semantics methods ([LSI](http://lsa3.colorado.edu/papers/JASIS.lsi.90.pdf) **[5 points]** and [LDA](https://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf) **[5 points]**) for retrieval.\n",
    "\n",
    "You do not need to implement LSI or LDA on your own. Instead, you can use [gensim](http://radimrehurek.com/gensim/index.html). An example on how to integrate Pyndri with Gensim for word2vec can be found [here](https://github.com/cvangysel/pyndri/blob/master/examples/word2vec.py). For the remaining latent vector space models, you will need to implement connector classes (such as `IndriSentences`) by yourself.\n",
    "\n",
    "In order to use a latent semantic model for retrieval, you need to:\n",
    "   * build a representation of the query **q**,\n",
    "   * build a representation of the document **d**,\n",
    "   * calculate the similarity between **q** and **d** (e.g., cosine similarity, KL-divergence).\n",
    "     \n",
    "The exact implementation here depends on the latent semantic model you are using. \n",
    "   \n",
    "Each of these LSMs come with various hyperparameters to tune. Make a choice on the parameters, and explicitly mention the reasons that led you to these decisions. You can use the validation set to optimize hyper parameters you see fit; motivate your decisions. In addition, mention clearly how the query/document representations were constructed for each LSM and explain your choices.\n",
    "\n",
    "In this experiment, you will first obtain an initial top-1000 ranking for each query using TF-IDF in **Task 1**, and then re-rank the documents using the LSMs. Use TREC Eval to obtain the results and report on `NDCG@10`, Mean Average Precision (`MAP@1000`), `Precision@5` and `Recall@1000`.\n",
    "\n",
    "Perform significance testing **[5 points]** (similar as in Task 1) in the class of semantic matching methods.\n",
    "\n",
    "Perform analysis **[5 points]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connector class pyndri - gensim\n",
    "class IndriTermDocFreq(gensim.interfaces.CorpusABC):\n",
    "    \"\"\"Integrates an Index with Gensim's word2vec implementation.\"\"\"\n",
    "\n",
    "    def __init__(self, index, dictionary, list_docs = None, max_documents=None):\n",
    "        assert isinstance(index, pyndri.Index)\n",
    "\n",
    "        self.index = index\n",
    "        self.dictionary = dictionary\n",
    "        self.list_docs = list_docs\n",
    "        self.max_documents = max_documents\n",
    "\n",
    "    def _maximum_document(self):\n",
    "        if self.max_documents is None:\n",
    "            return self.index.maximum_document()\n",
    "        else:\n",
    "            return min(\n",
    "                self.max_documents + self.index.document_base(),\n",
    "                self.index.maximum_document())\n",
    "\n",
    "    def __iter__(self):\n",
    "        \n",
    "        if self.list_docs:\n",
    "            rng = self.list_docs\n",
    "        else:\n",
    "            rng = range(self.index.document_base(), self._maximum_document())\n",
    "#         print(rng[:5],len(rng))\n",
    "        \n",
    "        for int_doc_id in rng:\n",
    "            _, tokens = self.index.document(int_doc_id)\n",
    "            \n",
    "            yield [(key,len(list(group)) ) for  key, group in groupby(sorted(list(tokens))) if key>0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._maximum_document() - self.index.document_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_queries(queries, model):\n",
    "    \"\"\"\n",
    "    Given the ordered dict queries and an lsi model, transform the queries to the latent space\n",
    "    \"\"\"\n",
    "    transformed_queries = {}\n",
    "    for q_id in queries:\n",
    "#         print(tokenized_queries[q_id])\n",
    "#         print([(key,len(list(group)) ) for  key, group in groupby(tokenized_queries[q_id]) if key>0])\n",
    "        transformed_queries[q_id] = model[[(key,len(list(group)) ) for  key, group in groupby(tokenized_queries[q_id]) if key>0]]\n",
    "    return transformed_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parse rank from tf-idf.run file and create gensim index for each query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "extDocId2id={}\n",
    "for id in range(index.document_base(), index.maximum_document()):\n",
    "    extDocId2id[index.ext_document_id(id)] = id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_rank = defaultdict(list)\n",
    "\n",
    "with open('./retrievals/tf-idf.run', 'r') as file:\n",
    "    for line in file.readlines():\n",
    "        q_id = line.split()[0]\n",
    "        doc_id = line.split()[2]\n",
    "        tfidf_rank[q_id].append(extDocId2id[doc_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensim_rank(model, tfidf_rank, transformed_queries):\n",
    "    \"\"\"\n",
    "    Generates new ranking for each query, based on 1000 top TF-IDF results\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    ranking_new = {}\n",
    "    for q_id in queries.keys():\n",
    "    # for q_id in ['100','101']:\n",
    "        top1000 = tfidf_rank[q_id]\n",
    "        gimme_docs = IndriTermDocFreq(index,dictionary,list_docs=top1000)\n",
    "        gensim_index = gensim.similarities.MatrixSimilarity(model[gimme_docs], num_features = model.num_topics)\n",
    "\n",
    "        sims = gensim_index[transformed_queries[q_id]]\n",
    "        ranking_new[q_id] = tuple(zip(sims,map(lambda x: index.ext_document_id(x), top1000)))\n",
    "\n",
    "    print(\"took %i sec for %i latent dims\"%(time.time() - start_time ,model.num_topics))\n",
    "    return ranking_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_retrieval(model_name,ranking_dict):\n",
    "    run_out_path = 'retrievals/'+model_name\n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name=model_name,\n",
    "            data=ranking_dict,\n",
    "            out_f=f_out,\n",
    "            max_objects_per_query=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function to score individual query-document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensim_rank_pair(doc_id,q_id, model, transformed_queries):\n",
    "    \"\"\"\n",
    "    Generates new ranking for each doc-id () query pair, for the given model (LSI or LDA)\n",
    "    \"\"\"\n",
    "    lda_vec1 = model[IndriTermDocFreq(index,dictionary,list_docs=[doc_id])]\n",
    "    lda_vec2 = transformed_queries[q_id]\n",
    "    return gensim.matutils.cossim(list(lda_vec1)[0],lda_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_results(model_name):\n",
    "    print(model_name)\n",
    "    r_fname = 'retrievals/'+model_name\n",
    "    print(\"Validation\")\n",
    "    !trec_eval -m all_trec ./ap_88_89/qrel_validation {r_fname} | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\"\n",
    "    print(\"Test\")\n",
    "    !trec_eval -m all_trec ./ap_88_89/qrel_test {r_fname} | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate lsi model\n",
    "lsi = gensim.models.LsiModel(id2word=id2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsi with 300 topics took 671.6262338161469 sec\n",
      "lsi/lsi_counts300.mod\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lsi/lsi_counts300.mod.projection.u.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved %s object\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: file must have a 'write' attribute",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-238-6e6f476f67c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lsi with %i topics took %s sec'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_top\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mlsi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/models/lsimodel.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fname, *args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \"\"\"\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.projection'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLsiModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'projection'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dispatcher'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fname_or_handle, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved %s object\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# `fname_or_handle` does not have write attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparately\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep_limit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36m_smart_save\u001b[0;34m(self, fname, separately, sep_limit, ignore, pickle_protocol)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         restores = self._save_specials(fname, separately, sep_limit, ignore, pickle_protocol,\n\u001b[0;32m--> 370\u001b[0;31m                                        compress, subname)\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0mpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36m_save_specials\u001b[0;34m(self, fname, separately, sep_limit, ignore, pickle_protocol, compress, subname)\u001b[0m\n\u001b[1;32m    422\u001b[0m                         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez_compressed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m                         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsc_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mattrib\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lsi/lsi_counts300.mod.projection.u.npy'"
     ]
    }
   ],
   "source": [
    "#create LSI for different # dimensions (if not in disk)\n",
    "\n",
    "# generator for passing counts of documents from pyndri to gensim\n",
    "wordfreq = IndriTermDocFreq(index,dictionary)\n",
    "\n",
    "# for n_top in [10,50,100, 150,200, 250,300,400, 500]:\n",
    "for n_top in [300]:\n",
    "    fname = 'lsi/lsi_counts%i.mod'%n_top\n",
    "\n",
    "    if os.path.exists(fname)==False:\n",
    "        start_time = time.time()\n",
    "        lsi = gensim.models.LsiModel(corpus = wordfreq,\n",
    "                                     id2word=id2token,\n",
    "                                     num_topics=n_top)\n",
    "        print('lsi with %i topics took %s sec'%(n_top,time.time()-start_time))\n",
    "        print(fname)\n",
    "        lsi.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi.save('lsi/lsi_counts300.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select appropriate lsi file:\n",
    "fname = 'lsi/lsi_counts300.mod'\n",
    "lsi = gensim.models.LsiModel.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_queries = transform_queries(queries, lsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start a new rank on the 1000 docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select model\n",
    "model = lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 106 sec for 300 latent dims\n"
     ]
    }
   ],
   "source": [
    "rr = gensim_rank(model, tfidf_rank=tfidf_rank, transformed_queries=transformed_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'lsi_300'\n",
    "save_retrieval(model_name, rr)\n",
    "\n",
    "r_fname = 'retrievals/'+model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lsi_300\n",
      "Validation\n",
      "P_5                   \tall\t0.1600\n",
      "recall_1000           \tall\t0.5766\n",
      "ndcg_cut_10           \tall\t0.1720\n",
      "map_cut_1000          \tall\t0.1161\n",
      "Test\n",
      "P_5                   \tall\t0.1550\n",
      "recall_1000           \tall\t0.5352\n",
      "ndcg_cut_10           \tall\t0.1466\n",
      "map_cut_1000          \tall\t0.0831\n"
     ]
    }
   ],
   "source": [
    "evaluation_results(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda with 50 topics took 1710.3404812812805 sec\n",
      "lda/lda_50\n"
     ]
    }
   ],
   "source": [
    "#create LDA for different # topics (if not in disk)\n",
    "\n",
    "# generator for passing counts of documents from pyndri to gensim\n",
    "wordfreq = IndriTermDocFreq(index,dictionary)\n",
    "\n",
    "# for n_top in [10,50]:\n",
    "for n_top in [50]:\n",
    "    model_name = 'lda_'+str(n_top)\n",
    "    fname = 'lda/%s'%model_name\n",
    "\n",
    "    if os.path.exists(fname)==False:\n",
    "        start_time = time.time()\n",
    "        lda = gensim.models.ldamulticore.LdaMulticore(corpus = wordfreq,\n",
    "                                     id2word=id2token,\n",
    "#                                      alpha='auto',\n",
    "                                     minimum_probability=0,\n",
    "                                     num_topics=n_top)\n",
    "        print('lda with %i topics took %s sec'%(n_top,time.time()-start_time))\n",
    "        print(fname)\n",
    "        lda.save(fname)\n",
    "        \n",
    "    else:\n",
    "        print(model_name,'already exists on disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select / load model\n",
    "model_name = 'lda_50'\n",
    "model = gensim.models.ldamulticore.LdaModel.load('lda/'+model_name)\n",
    "model.minimum_probability=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_lda = transform_queries(queries, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 1199 sec for 50 latent dims\n"
     ]
    }
   ],
   "source": [
    "# check if retrieval file exists already\n",
    "r_fname = 'retrievals/'+model_name\n",
    "if os.path.exists(r_fname)==False:\n",
    "    rr = gensim_rank(model, tfidf_rank=tfidf_rank, transformed_queries=transformed_lda)\n",
    "    save_retrieval(model_name,rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda_50\n",
      "Validation\n",
      "P_5                   \tall\t0.1733\n",
      "recall_1000           \tall\t0.5766\n",
      "ndcg_cut_10           \tall\t0.1877\n",
      "map_cut_1000          \tall\t0.1312\n",
      "Test\n",
      "P_5                   \tall\t0.1550\n",
      "recall_1000           \tall\t0.5352\n",
      "ndcg_cut_10           \tall\t0.1421\n",
      "map_cut_1000          \tall\t0.0854\n"
     ]
    }
   ],
   "source": [
    "evaluation_results(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3:  Word embeddings for ranking [10 points] ###\n",
    "\n",
    "First create word embeddings on the corpus we provided using [word2vec](http://arxiv.org/abs/1411.2738) -- [gensim implementation](https://radimrehurek.com/gensim/models/word2vec.html). You should extract the indexed documents using pyndri and provide them to gensim for training a model (see example [here](https://github.com/nickvosk/pyndri/blob/master/examples/word2vec.py)).\n",
    "\n",
    "Try one of the following (increasingly complex) methods for building query and document representations:\n",
    "   * Average or sum the word vectors.\n",
    "   * Cluster words in the document using [k-means](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) and use the centroid of the most important cluster. Experiment with different values of K for k-means.\n",
    "   * Using the [bag-of-word-embeddings representation](https://ciir-publications.cs.umass.edu/pub/web/getpdf.php?id=1248).\n",
    "   \n",
    "Note that since we provide the implementation for training word2vec, you will be graded based on your creativity on combining word embeddings for building query and document representations.\n",
    "\n",
    "Note: If you want to experiment with pre-trained word embeddings on a different corpus, you can use the word embeddings we provide alongside the assignment (./data/reduced_vectors_google.txt). These are the [google word2vec word embeddings](https://code.google.com/archive/p/word2vec/), reduced to only the words that appear in the document collection we use in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing word2vec.\n",
      "Loading vocabulary.\n",
      "Constructing word2vec vocabulary.\n",
      "Word2Vec(vocab=267318, size=300, alpha=0.025)\n",
      "Elapsed time: 54.02387189865112\n"
     ]
    }
   ],
   "source": [
    "## Create embeddings\n",
    "start_time = time.time()\n",
    "print('Initializing word2vec.')\n",
    "\n",
    "word2vec_init = gensim.models.Word2Vec(\n",
    "    size=300,  # Embedding size\n",
    "    window=5,  # One-sided window size\n",
    "    sg=True,  # Skip-gram.\n",
    "    min_count=1,  # Minimum word frequency.\n",
    "    sample=1e-3,  # Sub-sample threshold.\n",
    "    hs=False,  # Hierarchical softmax.\n",
    "    negative=10,  # Number of negative examples.\n",
    "    iter=1,  # Number of iterations.\n",
    "    workers=8,  # Number of workers.\n",
    ")\n",
    "\n",
    "index = pyndri.Index('index/')\n",
    "\n",
    "print('Loading vocabulary.')\n",
    "dictionary = pyndri.extract_dictionary(index)\n",
    "sentences = pyndri.compat.IndriSentences(index, dictionary)\n",
    "\n",
    "print('Constructing word2vec vocabulary.')\n",
    "\n",
    "# Build vocab.\n",
    "word2vec_init.build_vocab(sentences, trim_rule=None)\n",
    "model = word2vec_init\n",
    "# Normalize vectors\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# models = [word2vec_init]\n",
    "\n",
    "# for epoch in range(1, 1 + 1):\n",
    "#     print('Epoch ', epoch)\n",
    "#     epoch_time = time.time()\n",
    "    \n",
    "#     model = copy.deepcopy(models[-1])\n",
    "#     model.train(sentences, total_examples = model.corpus_count, epochs=model.iter)\n",
    "\n",
    "#     models.append(model)\n",
    "#     print('Elapsed time for model', epoch, ':', time.time() - epoch_time)\n",
    "\n",
    "print(model)\n",
    "print('Elapsed time:', time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_w2v_retrieval(model_name, score_fn, **args):\n",
    "    \"\"\"\n",
    "    Runs a retrieval method for all the queries and writes the TREC-friendly results in a file.\n",
    "    \n",
    "    :param model_name: the name of the model (a string)\n",
    "    :param score_fn: the scoring function (a function - see below for an example) \n",
    "    \"\"\"\n",
    "    run_out_path = '{}.run'.format(model_name)\n",
    "\n",
    "    if os.path.exists(run_out_path):\n",
    "        return\n",
    "\n",
    "    retrieval_start_time = time.time()\n",
    "\n",
    "    print('Retrieving using', model_name)\n",
    "\n",
    "    data = {}\n",
    "    \n",
    "    for qid in tokenized_queries.keys(): #for each query\n",
    "#     for qid in ['93']: #test\n",
    "\n",
    "        score = {}\n",
    "        \n",
    "        for query_term_id in tokenized_queries[qid]: #for each word_id in query\n",
    "\n",
    "            for (int_document_id,document_term_freq) in zip(inverted_index[query_term_id].keys(),inverted_index[query_term_id].values()):\n",
    "                #for each document where the word appears, calculate scoring function increment its score\n",
    "                new_score = score_fn(int_document_id, qid)\n",
    "                \n",
    "                if int_document_id not in score.keys():\n",
    "                    #print('initiallizing and incrementing score')\n",
    "                    score[int_document_id] = new_score\n",
    "                else:\n",
    "                    #print('incrementing score')\n",
    "                    score[int_document_id] += new_score\n",
    "\n",
    "        #turn dict to list of tuples and continue        \n",
    "        # The dictionary data should have the form: query_id --> (document_score, external_doc_id)\n",
    "        data[qid] = [(score, index.ext_document_id(doc_id)) for (score, doc_id) in zip(score.values(), score.keys())]\n",
    "                \n",
    "#     write out\n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name=model_name,\n",
    "            data=data,\n",
    "            out_f=f_out,\n",
    "\n",
    "            max_objects_per_query=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "## Sum all query vectors (normalized)\n",
    "summed_queries = {}\n",
    "for qid in tokenized_queries.keys(): #for each query\n",
    "    \n",
    "    Q = []\n",
    "    for query_term_id in tokenized_queries[qid]: #for each word_id in query\n",
    "        term = dictionary[query_term_id]\n",
    "        Q.append(model[term])\n",
    "        \n",
    "    Q = np.array(Q)\n",
    "    vector = Q.sum(axis=0) \n",
    "    vector = vector / np.sqrt((vector ** 2).sum())\n",
    "\n",
    "    summed_queries[qid] = vector   \n",
    "\n",
    "## Sum all document vectors (normalized)    \n",
    "summed_docs = {}\n",
    "for int_doc_id in range(index.document_base(), index.maximum_document()):\n",
    "    ext_doc_id, doc_token_ids = index.document(int_doc_id)\n",
    "        \n",
    "    D = []\n",
    "    for token_id in doc_token_ids: \n",
    "        if token_id > 0:\n",
    "            term = dictionary[query_term_id]\n",
    "            D.append(model[term])\n",
    "    D = np.array(D)\n",
    "    vector = D.sum(axis=0) \n",
    "    vector = vector / np.sqrt((vector ** 2).sum())\n",
    "\n",
    "    summed_docs[int_doc_id] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summed_vectors(document_id, query_id):\n",
    "    \"\"\"\n",
    "    Scoring function for a document and a query term\n",
    "    \n",
    "    :param document_id: the document id\n",
    "    :param query_id: the tokenized query id\n",
    "    \"\"\"\n",
    "    \n",
    "    cosine_similarity = np.dot(summed_queries[query_id], summed_docs[document_id])/(np.linalg.norm(summed_queries[query_id])* np.linalg.norm(summed_docs[document_id]))\n",
    "        \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "run_w2v_retrieval('retrievals/summed_vectors',summed_vectors)\n",
    "\n",
    "print ('elapsed time:',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_5                   \tall\t0.1667\n",
      "recall_1000           \tall\t0.3729\n",
      "ndcg_cut_10           \tall\t0.1446\n",
      "map_cut_1000          \tall\t0.0886\n",
      "\n",
      "\n",
      "P_5                   \tall\t0.1367\n",
      "recall_1000           \tall\t0.3230\n",
      "ndcg_cut_10           \tall\t0.1263\n",
      "map_cut_1000          \tall\t0.0583\n"
     ]
    }
   ],
   "source": [
    "# trec_eval command for evalutaion of summed_vectors\n",
    "!trec_eval -m all_trec ./ap_88_89/qrel_validation retrievals/summed_vectors.run | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\"\n",
    "print('\\n')\n",
    "\n",
    "# trec_eval command for test of summed_vectors\n",
    "!trec_eval -m all_trec ./ap_88_89/qrel_test retrievals/summed_vectors.run | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaged_vectors(document_id, query_id):\n",
    "    \"\"\"\n",
    "    Scoring function for a document and a query term\n",
    "    \n",
    "    :param document_id: the document id\n",
    "    :param query_id: the tokenized query id\n",
    "    \"\"\"\n",
    "    \n",
    "    query_vector = summed_queries[query_id] / len(tokenized_queries[qid])\n",
    "    doc_vector = summed_docs[document_id] / document_lengths[document_id]\n",
    "    \n",
    "    \n",
    "    cosine_similarity = np.dot(query_vector, doc_vector)/(np.linalg.norm(query_vector)* np.linalg.norm(doc_vector))\n",
    "        \n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "run_w2v_retrieval('retrievals/averaged_vectors',averaged_vectors)\n",
    "\n",
    "print ('elapsed time:',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_5                   \tall\t0.1400\n",
      "recall_1000           \tall\t0.3736\n",
      "ndcg_cut_10           \tall\t0.1462\n",
      "map_cut_1000          \tall\t0.0886\n",
      "\n",
      "\n",
      "P_5                   \tall\t0.1283\n",
      "recall_1000           \tall\t0.3249\n",
      "ndcg_cut_10           \tall\t0.1295\n",
      "map_cut_1000          \tall\t0.0590\n"
     ]
    }
   ],
   "source": [
    "# trec_eval command for evalutaion of averaged vectors\n",
    "!trec_eval -m all_trec ./ap_88_89/qrel_validation retrievals/averaged_vectors.run | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\"\n",
    "print('\\n')\n",
    "\n",
    "# trec_eval command for test of averaged vectors\n",
    "!trec_eval -m all_trec ./ap_88_89/qrel_test retrievals/averaged_vectors.run | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Movers Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wmd_vectors(document_id, query_id):\n",
    "    \"\"\"\n",
    "    Scoring function for a document and a query term\n",
    "    \n",
    "    :param document_id: the document id\n",
    "    :param query_id: the tokenized query id\n",
    "    \"\"\"\n",
    "    \n",
    "    query = []\n",
    "    for query_term_id in tokenized_queries[query_id]: #for each word_id in query\n",
    "        term = dictionary[query_term_id]\n",
    "        query.append(term)\n",
    "            \n",
    "    document = []\n",
    "    \n",
    "    ext_doc_id, doc_token_ids = index.document(document_id)\n",
    "    for token_id in doc_token_ids: \n",
    "        if token_id > 0:\n",
    "            term = dictionary[query_term_id]\n",
    "            document.append(term)\n",
    "        \n",
    "    distance = model.wv.wmdistance(query, document)\n",
    "            \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "run_w2v_retrieval('retrievals/wmd_vectors',wmd_vectors)\n",
    "\n",
    "print ('elapsed time:',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_5                   \tall\t0.1867\n",
      "recall_1000           \tall\t0.5079\n",
      "ndcg_cut_10           \tall\t0.1859\n",
      "map_cut_1000          \tall\t0.1215\n",
      "\n",
      "\n",
      "P_5                   \tall\t0.2483\n",
      "recall_1000           \tall\t0.4965\n",
      "ndcg_cut_10           \tall\t0.2416\n",
      "map_cut_1000          \tall\t0.1180\n"
     ]
    }
   ],
   "source": [
    "# trec_eval command for evalutaion of averaged vectors\n",
    "!trec_eval -m all_trec ./ap_88_89/qrel_validation retrievals/wmd_vectors.run | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\"\n",
    "print('\\n')\n",
    "\n",
    "# trec_eval command for test of averaged vectors\n",
    "!trec_eval -m all_trec ./ap_88_89/qrel_test retrievals/wmd_vectors.run | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Learning to rank (LTR) [10 points] ###\n",
    "\n",
    "In this task you will get an introduction into learning to rank for information retrieval, in particular pointwise learning to rank.\n",
    "\n",
    "You will experiment with a pointwise learning to rank method, logistic regression, implemented in [scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "Train your LTR model using 10-fold cross validation on the test set.\n",
    "\n",
    "You can explore different ways for devising features for the model. Obviously, you can use the retrieval methods you implemented in Task 1 and Task 2 as features. Think about other features you can use (e.g. query/document length). \n",
    "One idea is to also explore external sources such as Wikipedia entities (?). Creativity on devising new features and providing motivation for them will be taken into account when grading.\n",
    "\n",
    "For every query, first create a document candidate set using the top-1000 documents using TF-IDF, and subsequently compute features given a query and a document. Note that the feature values of different retrieval methods are likely to be distributed differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create inverse mapping, because pyndri sucks\n",
    "extDocId2id={}\n",
    "for ext_id in range(index.document_base(), index.maximum_document()):\n",
    "    extDocId2id[index.ext_document_id(ext_id)] = ext_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def run_ltr_retrieval(score_fn, ext_id, qid, **args):\n",
    "    \"\"\"\n",
    "    Runs a retrieval method for all the queries and writes the TREC-friendly results in a file.\n",
    "    \n",
    "    :param model_name: the name of the model (a string)\n",
    "    :param score_fn: the scoring function (a function - see below for an example) \n",
    "    \"\"\"\n",
    "    retrieval_start_time = time.time()\n",
    "    \n",
    "    int_document_id = extDocId2id[ext_id]\n",
    "    qid = str(int(qid))\n",
    "    query_length = len(tokenized_queries[qid])\n",
    "\n",
    "    score = 0\n",
    "        #hack for BM25 (iterate duplicate terms in query once)\n",
    "    try:\n",
    "        if score_fn == bm25:\n",
    "            tokenized_queries[qid] = list(set(tokenized_queries[qid]))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for query_term_id in tokenized_queries[qid]: #for each word_id in query\n",
    "        if int_document_id in inverted_index[query_term_id].keys():\n",
    "            document_term_freq = inverted_index[query_term_id][int_document_id]\n",
    "        \n",
    "            #for each document where the word appears, calculate scoring function increment its score\n",
    "            if score_fn == dirichlet_prior or score_fn == absolute_discounting:\n",
    "                new_score = score_fn(int_document_id, query_term_id, document_term_freq, query_length, **args)\n",
    "      \n",
    "            elif score_fn == summed_vectors or score_fn == averaged_vectors or score_fn == wmd_vectors:\n",
    "                new_score = score_fn(int_document_id, qid)\n",
    "                \n",
    "            else:\n",
    "                new_score = score_fn(int_document_id, query_term_id, document_term_freq, **args)\n",
    "            score += new_score\n",
    "    \n",
    "    if np.isinf(score):\n",
    "        score = 0\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read test file ro create a new trainData dataframe\n",
    "path = \"./ap_88_89/qrel_test\"\n",
    "\n",
    "columns = ['query', '?', 'doc', 'result']\n",
    "\n",
    "trainData = pd.read_csv(path, delimiter=' ', header = None)\n",
    "trainData.columns = columns\n",
    "trainData = trainData.drop(columns=['?'])\n",
    "\n",
    "ne = ['AP900109-0232',\n",
    "'AP900214-0247',\n",
    "'AP900215-0091',\n",
    "'AP900327-0168',\n",
    "'AP900427-0031',\n",
    "'AP900429-0093',\n",
    "'AP900607-0165',\n",
    "'AP900904-0175',\n",
    "'AP900913-0007',\n",
    "'AP901121-0246']\n",
    "\n",
    "# Delete non existing\n",
    "trainData = trainData[~np.in1d(trainData.dRepoc, ne)]\n",
    "trainData.index = range(len(trainData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read existing data for quick updating\n",
    "trainData = pd.read_csv('trainData.csv', delimiter=',')\n",
    "trainData = trainData.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query length\n",
    "for idx, row in trainData.iterrows():\n",
    "    \n",
    "    score = len(tokenized_queries[str(trainData.iloc[idx]['query'])])\n",
    "    trainData.at[idx, 'query length'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dcoument length\n",
    "for idx, row in trainData.iterrows():\n",
    "    \n",
    "    doc_id = extDocId2id[trainData.iloc[idx]['doc']]\n",
    "    score = len(index.document(doc_id)[1])\n",
    "    trainData.at[idx, 'document length'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unique word in doc\n",
    "for idx, row in trainData.iterrows():\n",
    "    \n",
    "    doc_id = extDocId2id[trainData.iloc[idx]['doc']]\n",
    "    score = unique_terms_per_document[doc_id]\n",
    "    trainData.at[idx, 'document unique'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append TF-IDF data\n",
    "for idx, row in trainData.iterrows():\n",
    "\n",
    "    score = run_ltr_retrieval(tfidf, trainData.iloc[idx]['doc'], trainData.iloc[idx]['query'])\n",
    "    trainData.at[idx, 'tfidf'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append BM25 data\n",
    "for idx, row in trainData.iterrows():\n",
    "\n",
    "    score = run_ltr_retrieval(bm25, trainData.iloc[idx]['doc'], trainData.iloc[idx]['query'])\n",
    "    trainData.at[idx, 'bm25'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append Jelinek Mercer data\n",
    "for idx, row in trainData.iterrows():\n",
    "\n",
    "    score = run_ltr_retrieval(jelinek_mercer, trainData.iloc[idx]['doc'], trainData.iloc[idx]['query'])\n",
    "    trainData.at[idx, 'jelinek mercer'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append Dirichlet Prior data\n",
    "for idx, row in trainData.iterrows():\n",
    "\n",
    "    score = run_ltr_retrieval(dirichlet_prior, trainData.iloc[idx]['doc'], trainData.iloc[idx]['query'])\n",
    "    trainData.at[idx, 'dirichlet prior'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append Absolute Discounting data\n",
    "for idx, row in trainData.iterrows():\n",
    "\n",
    "    score = run_ltr_retrieval(absolute_discounting, trainData.iloc[idx]['doc'], trainData.iloc[idx]['query'])\n",
    "    trainData.at[idx, 'absolute discounting'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append Word2Vec Sum data\n",
    "for idx, row in trainData.iterrows():\n",
    "\n",
    "    score = run_ltr_retrieval(summed_vectors, trainData.iloc[idx]['doc'], trainData.iloc[idx]['query'])\n",
    "    trainData.at[idx, 'w2v: sum'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append Word2Vec Average data\n",
    "for idx, row in trainData.iterrows():\n",
    "\n",
    "    score = run_ltr_retrieval(averaged_vectors, trainData.iloc[idx]['doc'], trainData.iloc[idx]['query'])\n",
    "    trainData.at[idx, 'w2v: avg'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append Word2Vec WMD data\n",
    "for idx, row in trainData.iterrows():\n",
    "\n",
    "    score = run_ltr_retrieval(wmd_vectors, trainData.iloc[idx]['doc'], trainData.iloc[idx]['query'])\n",
    "    trainData.at[idx, 'w2v: wmd'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append LSI data\n",
    "for idx, row in trainData.iterrows():    \n",
    "        \n",
    "    external_id = extDocId2id[str(trainData.iloc[idx]['doc'])]\n",
    "\n",
    "    score = gensim_rank_pair(external_id, str(trainData.iloc[idx]['query']), lsi, transformed_queries)\n",
    "    trainData.at[idx, 'lsi'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append LDA data\n",
    "for idx, row in trainData.iterrows():    \n",
    "        \n",
    "    external_id = extDocId2id[str(trainData.iloc[idx]['doc'])]\n",
    "\n",
    "    score = gensim_rank_pair(external_id, str(trainData.iloc[idx]['query']), lda, transformed_queries)\n",
    "    trainData.at[idx, 'lda'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>doc</th>\n",
       "      <th>result</th>\n",
       "      <th>query length</th>\n",
       "      <th>document length</th>\n",
       "      <th>document unique</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>bm25</th>\n",
       "      <th>jelinek mercer</th>\n",
       "      <th>dirichlet prior</th>\n",
       "      <th>absolute discounting</th>\n",
       "      <th>w2v: sum</th>\n",
       "      <th>w2v: avg</th>\n",
       "      <th>w2v: wmd</th>\n",
       "      <th>lsi</th>\n",
       "      <th>lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880218-0195</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>769.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>24.020823</td>\n",
       "      <td>13.950561</td>\n",
       "      <td>3.216136</td>\n",
       "      <td>0.777933</td>\n",
       "      <td>31.724555</td>\n",
       "      <td>0.039118</td>\n",
       "      <td>0.039118</td>\n",
       "      <td>1.133204</td>\n",
       "      <td>0.219277</td>\n",
       "      <td>-0.062410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880229-0184</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>23.671856</td>\n",
       "      <td>18.590453</td>\n",
       "      <td>9.689087</td>\n",
       "      <td>4.906967</td>\n",
       "      <td>62.680648</td>\n",
       "      <td>0.078235</td>\n",
       "      <td>0.078235</td>\n",
       "      <td>2.266407</td>\n",
       "      <td>0.077448</td>\n",
       "      <td>-0.094482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880301-0033</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>35.006768</td>\n",
       "      <td>27.085821</td>\n",
       "      <td>16.471032</td>\n",
       "      <td>9.202167</td>\n",
       "      <td>93.959587</td>\n",
       "      <td>0.117352</td>\n",
       "      <td>0.117352</td>\n",
       "      <td>3.399611</td>\n",
       "      <td>0.089082</td>\n",
       "      <td>-0.082875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880302-0095</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>0.023027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880312-0116</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106967</td>\n",
       "      <td>-0.038606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880312-0142</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>43.604136</td>\n",
       "      <td>25.943141</td>\n",
       "      <td>11.048272</td>\n",
       "      <td>6.006798</td>\n",
       "      <td>61.030405</td>\n",
       "      <td>0.078235</td>\n",
       "      <td>0.078235</td>\n",
       "      <td>2.266407</td>\n",
       "      <td>0.441782</td>\n",
       "      <td>-0.062659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880314-0106</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046916</td>\n",
       "      <td>-0.049820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880318-0316</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>13.595374</td>\n",
       "      <td>11.748166</td>\n",
       "      <td>2.368201</td>\n",
       "      <td>0.091057</td>\n",
       "      <td>27.773922</td>\n",
       "      <td>0.039117</td>\n",
       "      <td>0.039117</td>\n",
       "      <td>1.133204</td>\n",
       "      <td>0.137957</td>\n",
       "      <td>-0.033829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880321-0194</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>33.587524</td>\n",
       "      <td>28.112019</td>\n",
       "      <td>15.916534</td>\n",
       "      <td>8.645984</td>\n",
       "      <td>93.301055</td>\n",
       "      <td>0.117352</td>\n",
       "      <td>0.117352</td>\n",
       "      <td>3.399611</td>\n",
       "      <td>0.108973</td>\n",
       "      <td>-0.014807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880321-0278</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>45.292147</td>\n",
       "      <td>41.796820</td>\n",
       "      <td>14.713149</td>\n",
       "      <td>7.002916</td>\n",
       "      <td>85.436913</td>\n",
       "      <td>0.117353</td>\n",
       "      <td>0.117353</td>\n",
       "      <td>3.399611</td>\n",
       "      <td>0.261607</td>\n",
       "      <td>0.024155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880322-0074</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>26.229972</td>\n",
       "      <td>25.244887</td>\n",
       "      <td>9.963387</td>\n",
       "      <td>5.052747</td>\n",
       "      <td>57.985625</td>\n",
       "      <td>0.078235</td>\n",
       "      <td>0.078235</td>\n",
       "      <td>2.266407</td>\n",
       "      <td>0.118421</td>\n",
       "      <td>-0.015223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880323-0016</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>36.655421</td>\n",
       "      <td>23.732055</td>\n",
       "      <td>9.978573</td>\n",
       "      <td>5.064910</td>\n",
       "      <td>64.484407</td>\n",
       "      <td>0.078235</td>\n",
       "      <td>0.078235</td>\n",
       "      <td>2.266407</td>\n",
       "      <td>0.180224</td>\n",
       "      <td>-0.059052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880328-0129</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>24.020823</td>\n",
       "      <td>16.063962</td>\n",
       "      <td>3.607029</td>\n",
       "      <td>1.183174</td>\n",
       "      <td>30.370550</td>\n",
       "      <td>0.039117</td>\n",
       "      <td>0.039117</td>\n",
       "      <td>1.133204</td>\n",
       "      <td>0.230948</td>\n",
       "      <td>0.023751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880401-0259</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>31.505102</td>\n",
       "      <td>27.179685</td>\n",
       "      <td>7.081691</td>\n",
       "      <td>2.324797</td>\n",
       "      <td>57.376964</td>\n",
       "      <td>0.078235</td>\n",
       "      <td>0.078235</td>\n",
       "      <td>2.266407</td>\n",
       "      <td>0.114459</td>\n",
       "      <td>-0.079686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880407-0029</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>26.923625</td>\n",
       "      <td>14.764672</td>\n",
       "      <td>3.557006</td>\n",
       "      <td>1.111895</td>\n",
       "      <td>31.641198</td>\n",
       "      <td>0.039118</td>\n",
       "      <td>0.039118</td>\n",
       "      <td>1.133204</td>\n",
       "      <td>0.257056</td>\n",
       "      <td>-0.050479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880410-0026</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>909.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>38.468804</td>\n",
       "      <td>19.604005</td>\n",
       "      <td>10.722845</td>\n",
       "      <td>5.647920</td>\n",
       "      <td>68.847608</td>\n",
       "      <td>0.078236</td>\n",
       "      <td>0.078236</td>\n",
       "      <td>2.266407</td>\n",
       "      <td>0.165437</td>\n",
       "      <td>-0.035594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880411-0040</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>30.039677</td>\n",
       "      <td>23.954588</td>\n",
       "      <td>11.064524</td>\n",
       "      <td>6.120394</td>\n",
       "      <td>63.455016</td>\n",
       "      <td>0.078235</td>\n",
       "      <td>0.078235</td>\n",
       "      <td>2.266407</td>\n",
       "      <td>0.164298</td>\n",
       "      <td>-0.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880411-0275</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>24.020823</td>\n",
       "      <td>19.370401</td>\n",
       "      <td>4.425484</td>\n",
       "      <td>1.682966</td>\n",
       "      <td>26.917663</td>\n",
       "      <td>0.039118</td>\n",
       "      <td>0.039118</td>\n",
       "      <td>1.133204</td>\n",
       "      <td>0.378700</td>\n",
       "      <td>-0.033502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880413-0329</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>25.895154</td>\n",
       "      <td>28.308417</td>\n",
       "      <td>6.950129</td>\n",
       "      <td>2.102079</td>\n",
       "      <td>52.846040</td>\n",
       "      <td>0.078235</td>\n",
       "      <td>0.078235</td>\n",
       "      <td>2.266407</td>\n",
       "      <td>0.158616</td>\n",
       "      <td>-0.055196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880419-0268</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>30.910133</td>\n",
       "      <td>15.658844</td>\n",
       "      <td>4.065621</td>\n",
       "      <td>1.609314</td>\n",
       "      <td>31.602738</td>\n",
       "      <td>0.039117</td>\n",
       "      <td>0.039117</td>\n",
       "      <td>1.133204</td>\n",
       "      <td>0.329308</td>\n",
       "      <td>-0.055557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880426-0085</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064111</td>\n",
       "      <td>-0.012897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880505-0044</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023471</td>\n",
       "      <td>-0.006151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880505-0085</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023259</td>\n",
       "      <td>-0.016838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880505-0250</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036204</td>\n",
       "      <td>-0.005327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880507-0024</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>913.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>24.020823</td>\n",
       "      <td>12.800212</td>\n",
       "      <td>3.021524</td>\n",
       "      <td>0.518863</td>\n",
       "      <td>32.440305</td>\n",
       "      <td>0.039118</td>\n",
       "      <td>0.039118</td>\n",
       "      <td>1.133204</td>\n",
       "      <td>0.150489</td>\n",
       "      <td>-0.056878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880511-0059</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>19.963196</td>\n",
       "      <td>14.738112</td>\n",
       "      <td>3.122591</td>\n",
       "      <td>0.748700</td>\n",
       "      <td>30.103440</td>\n",
       "      <td>0.039117</td>\n",
       "      <td>0.039117</td>\n",
       "      <td>1.133204</td>\n",
       "      <td>0.130421</td>\n",
       "      <td>-0.023533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880511-0261</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>733.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>57.252348</td>\n",
       "      <td>27.813724</td>\n",
       "      <td>9.085190</td>\n",
       "      <td>4.132236</td>\n",
       "      <td>64.958622</td>\n",
       "      <td>0.078235</td>\n",
       "      <td>0.078235</td>\n",
       "      <td>2.266407</td>\n",
       "      <td>0.224348</td>\n",
       "      <td>-0.047750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880512-0017</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>67.592585</td>\n",
       "      <td>35.245179</td>\n",
       "      <td>14.943210</td>\n",
       "      <td>7.472491</td>\n",
       "      <td>96.808983</td>\n",
       "      <td>0.117353</td>\n",
       "      <td>0.117353</td>\n",
       "      <td>3.399611</td>\n",
       "      <td>0.242720</td>\n",
       "      <td>-0.051928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880512-0051</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>13.595374</td>\n",
       "      <td>15.769942</td>\n",
       "      <td>3.041577</td>\n",
       "      <td>0.648024</td>\n",
       "      <td>25.001333</td>\n",
       "      <td>0.039118</td>\n",
       "      <td>0.039118</td>\n",
       "      <td>1.133204</td>\n",
       "      <td>0.133109</td>\n",
       "      <td>-0.045196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>68</td>\n",
       "      <td>AP880512-0264</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>33.586541</td>\n",
       "      <td>12.504489</td>\n",
       "      <td>3.683279</td>\n",
       "      <td>0.986592</td>\n",
       "      <td>34.482659</td>\n",
       "      <td>0.039118</td>\n",
       "      <td>0.039118</td>\n",
       "      <td>1.133204</td>\n",
       "      <td>0.269300</td>\n",
       "      <td>-0.013641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49496</th>\n",
       "      <td>113</td>\n",
       "      <td>AP890906-0048</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>33.637593</td>\n",
       "      <td>36.162298</td>\n",
       "      <td>12.237254</td>\n",
       "      <td>5.297046</td>\n",
       "      <td>41.184266</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>2.121832</td>\n",
       "      <td>0.336184</td>\n",
       "      <td>-0.035296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49497</th>\n",
       "      <td>113</td>\n",
       "      <td>AP890929-0219</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>71.764075</td>\n",
       "      <td>35.213800</td>\n",
       "      <td>10.641305</td>\n",
       "      <td>4.378302</td>\n",
       "      <td>77.110509</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>-0.007665</td>\n",
       "      <td>3.182748</td>\n",
       "      <td>0.472326</td>\n",
       "      <td>-0.051060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49498</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891004-0241</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>15.487444</td>\n",
       "      <td>15.732500</td>\n",
       "      <td>6.223210</td>\n",
       "      <td>3.170443</td>\n",
       "      <td>22.539682</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>1.060916</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>-0.038076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49499</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891014-0089</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>57.361585</td>\n",
       "      <td>40.919621</td>\n",
       "      <td>10.619763</td>\n",
       "      <td>4.576913</td>\n",
       "      <td>72.458072</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>3.182748</td>\n",
       "      <td>0.233094</td>\n",
       "      <td>-0.039196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49500</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891016-0021</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>50.038807</td>\n",
       "      <td>27.097001</td>\n",
       "      <td>11.040341</td>\n",
       "      <td>6.380163</td>\n",
       "      <td>54.019147</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>2.121832</td>\n",
       "      <td>0.428973</td>\n",
       "      <td>-0.056378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49501</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891020-0260</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>16.228950</td>\n",
       "      <td>19.071795</td>\n",
       "      <td>1.378891</td>\n",
       "      <td>-0.165378</td>\n",
       "      <td>18.284711</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>1.060916</td>\n",
       "      <td>0.105895</td>\n",
       "      <td>-0.132754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49502</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891021-0138</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>49.047187</td>\n",
       "      <td>50.307231</td>\n",
       "      <td>11.682494</td>\n",
       "      <td>4.841506</td>\n",
       "      <td>63.984861</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>3.182748</td>\n",
       "      <td>0.368340</td>\n",
       "      <td>-0.031285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49503</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891027-0195</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>51.662906</td>\n",
       "      <td>48.863225</td>\n",
       "      <td>11.834895</td>\n",
       "      <td>5.139858</td>\n",
       "      <td>64.948320</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>3.182748</td>\n",
       "      <td>0.355992</td>\n",
       "      <td>-0.004944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49504</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891102-0122</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>29.287975</td>\n",
       "      <td>21.216045</td>\n",
       "      <td>2.026155</td>\n",
       "      <td>0.108900</td>\n",
       "      <td>22.072138</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>1.060916</td>\n",
       "      <td>0.279663</td>\n",
       "      <td>0.002111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49505</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891103-0147</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>36.523202</td>\n",
       "      <td>34.357447</td>\n",
       "      <td>11.668490</td>\n",
       "      <td>5.532387</td>\n",
       "      <td>44.214704</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>2.121832</td>\n",
       "      <td>0.306970</td>\n",
       "      <td>-0.046754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49506</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891103-0244</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>16.228950</td>\n",
       "      <td>20.871719</td>\n",
       "      <td>1.617424</td>\n",
       "      <td>-0.045888</td>\n",
       "      <td>17.429918</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>1.060916</td>\n",
       "      <td>0.123349</td>\n",
       "      <td>-0.074943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49507</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891106-0189</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>61.357772</td>\n",
       "      <td>44.494273</td>\n",
       "      <td>10.454415</td>\n",
       "      <td>4.160804</td>\n",
       "      <td>75.573772</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>3.182748</td>\n",
       "      <td>0.290200</td>\n",
       "      <td>-0.141253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49508</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891107-0096</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>32.818237</td>\n",
       "      <td>33.053758</td>\n",
       "      <td>11.271225</td>\n",
       "      <td>5.230081</td>\n",
       "      <td>42.399839</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>2.121832</td>\n",
       "      <td>0.311952</td>\n",
       "      <td>-0.016285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49509</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891110-0008</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>24.137315</td>\n",
       "      <td>22.280646</td>\n",
       "      <td>2.014322</td>\n",
       "      <td>0.104285</td>\n",
       "      <td>20.530031</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>1.060916</td>\n",
       "      <td>0.247593</td>\n",
       "      <td>-0.068702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49510</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891111-0103</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>43.581461</td>\n",
       "      <td>26.141627</td>\n",
       "      <td>10.094702</td>\n",
       "      <td>5.350156</td>\n",
       "      <td>50.007556</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>-0.005111</td>\n",
       "      <td>2.121832</td>\n",
       "      <td>0.485381</td>\n",
       "      <td>-0.188554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49511</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891114-0116</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>67.003091</td>\n",
       "      <td>42.411812</td>\n",
       "      <td>11.743638</td>\n",
       "      <td>5.627640</td>\n",
       "      <td>74.247905</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>3.182748</td>\n",
       "      <td>0.491776</td>\n",
       "      <td>-0.052499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49512</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891114-0172</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>66.910222</td>\n",
       "      <td>39.596638</td>\n",
       "      <td>11.267038</td>\n",
       "      <td>5.206848</td>\n",
       "      <td>75.118470</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>3.182748</td>\n",
       "      <td>0.489864</td>\n",
       "      <td>-0.062305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49513</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891115-0047</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>52.942934</td>\n",
       "      <td>27.991641</td>\n",
       "      <td>11.387931</td>\n",
       "      <td>6.642451</td>\n",
       "      <td>53.425864</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>2.121832</td>\n",
       "      <td>0.468551</td>\n",
       "      <td>-0.042159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49514</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891118-0018</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>44.715499</td>\n",
       "      <td>27.960607</td>\n",
       "      <td>10.435033</td>\n",
       "      <td>5.722464</td>\n",
       "      <td>52.533873</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>2.121832</td>\n",
       "      <td>0.356342</td>\n",
       "      <td>-0.055172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49515</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891123-0016</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>34.293268</td>\n",
       "      <td>30.642739</td>\n",
       "      <td>10.631747</td>\n",
       "      <td>5.230461</td>\n",
       "      <td>45.080384</td>\n",
       "      <td>-0.005111</td>\n",
       "      <td>-0.005111</td>\n",
       "      <td>2.121832</td>\n",
       "      <td>0.295204</td>\n",
       "      <td>-0.057757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49516</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891129-0145</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>38.516916</td>\n",
       "      <td>33.537278</td>\n",
       "      <td>11.660510</td>\n",
       "      <td>5.749566</td>\n",
       "      <td>45.681682</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>2.121832</td>\n",
       "      <td>0.317193</td>\n",
       "      <td>-0.057658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49517</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891201-0039</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>36.523202</td>\n",
       "      <td>31.500853</td>\n",
       "      <td>10.501033</td>\n",
       "      <td>5.213408</td>\n",
       "      <td>47.642248</td>\n",
       "      <td>-0.005111</td>\n",
       "      <td>-0.005111</td>\n",
       "      <td>2.121832</td>\n",
       "      <td>0.372028</td>\n",
       "      <td>-0.032474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49518</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891202-0087</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>70.932540</td>\n",
       "      <td>38.938908</td>\n",
       "      <td>11.859856</td>\n",
       "      <td>5.793138</td>\n",
       "      <td>76.672251</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>3.182748</td>\n",
       "      <td>0.466252</td>\n",
       "      <td>-0.072006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49519</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891206-0060</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>26.184483</td>\n",
       "      <td>17.879548</td>\n",
       "      <td>5.641419</td>\n",
       "      <td>2.742469</td>\n",
       "      <td>23.178359</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>1.060916</td>\n",
       "      <td>0.477938</td>\n",
       "      <td>-0.110388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49520</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891207-0075</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>67.665283</td>\n",
       "      <td>40.815332</td>\n",
       "      <td>11.757627</td>\n",
       "      <td>5.683002</td>\n",
       "      <td>73.752148</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>3.182748</td>\n",
       "      <td>0.354611</td>\n",
       "      <td>-0.021904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49521</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891212-0026</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>56.955552</td>\n",
       "      <td>50.719785</td>\n",
       "      <td>11.744874</td>\n",
       "      <td>4.862820</td>\n",
       "      <td>67.433949</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>3.182748</td>\n",
       "      <td>0.384218</td>\n",
       "      <td>-0.007835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49522</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891212-0076</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>51.633477</td>\n",
       "      <td>46.837914</td>\n",
       "      <td>17.832061</td>\n",
       "      <td>9.129729</td>\n",
       "      <td>67.095717</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>3.182748</td>\n",
       "      <td>0.301389</td>\n",
       "      <td>0.002757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49523</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891213-0173</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>47.119802</td>\n",
       "      <td>31.216106</td>\n",
       "      <td>7.617506</td>\n",
       "      <td>3.548574</td>\n",
       "      <td>48.647406</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>2.121832</td>\n",
       "      <td>0.145526</td>\n",
       "      <td>-0.097167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49524</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891214-0025</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>64.721931</td>\n",
       "      <td>43.841140</td>\n",
       "      <td>10.852400</td>\n",
       "      <td>4.505996</td>\n",
       "      <td>72.755140</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>-0.007666</td>\n",
       "      <td>3.182748</td>\n",
       "      <td>0.276304</td>\n",
       "      <td>-0.081359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49525</th>\n",
       "      <td>113</td>\n",
       "      <td>AP891218-0021</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>21.841799</td>\n",
       "      <td>14.721796</td>\n",
       "      <td>6.838255</td>\n",
       "      <td>3.991388</td>\n",
       "      <td>24.534298</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>-0.002555</td>\n",
       "      <td>1.060916</td>\n",
       "      <td>0.185604</td>\n",
       "      <td>0.018077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49526 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       query            doc  result  query length  document length  \\\n",
       "0         68  AP880218-0195       1           5.0            769.0   \n",
       "1         68  AP880229-0184       1           5.0            657.0   \n",
       "2         68  AP880301-0033       1           5.0            613.0   \n",
       "3         68  AP880302-0095       0           5.0            522.0   \n",
       "4         68  AP880312-0116       1           5.0            374.0   \n",
       "5         68  AP880312-0142       0           5.0            442.0   \n",
       "6         68  AP880314-0106       1           5.0            574.0   \n",
       "7         68  AP880318-0316       0           5.0            630.0   \n",
       "8         68  AP880321-0194       1           5.0            567.0   \n",
       "9         68  AP880321-0278       0           5.0            318.0   \n",
       "10        68  AP880322-0074       1           5.0            394.0   \n",
       "11        68  AP880323-0016       0           5.0            659.0   \n",
       "12        68  AP880328-0129       0           5.0            573.0   \n",
       "13        68  AP880401-0259       0           5.0            504.0   \n",
       "14        68  AP880407-0029       0           5.0            705.0   \n",
       "15        68  AP880410-0026       1           5.0            909.0   \n",
       "16        68  AP880411-0040       1           5.0            432.0   \n",
       "17        68  AP880411-0275       1           5.0            199.0   \n",
       "18        68  AP880413-0329       0           5.0            378.0   \n",
       "19        68  AP880419-0268       0           5.0            634.0   \n",
       "20        68  AP880426-0085       1           5.0            219.0   \n",
       "21        68  AP880505-0044       1           5.0            389.0   \n",
       "22        68  AP880505-0085       0           5.0            413.0   \n",
       "23        68  AP880505-0250       0           5.0            807.0   \n",
       "24        68  AP880507-0024       0           5.0            913.0   \n",
       "25        68  AP880511-0059       1           5.0            581.0   \n",
       "26        68  AP880511-0261       0           5.0            733.0   \n",
       "27        68  AP880512-0017       0           5.0            707.0   \n",
       "28        68  AP880512-0051       0           5.0            299.0   \n",
       "29        68  AP880512-0264       0           5.0           1213.0   \n",
       "...      ...            ...     ...           ...              ...   \n",
       "49496    113  AP890906-0048       0           4.0             72.0   \n",
       "49497    113  AP890929-0219       0           4.0            796.0   \n",
       "49498    113  AP891004-0241       0           4.0            129.0   \n",
       "49499    113  AP891014-0089       0           4.0            518.0   \n",
       "49500    113  AP891016-0021       0           4.0            462.0   \n",
       "49501    113  AP891020-0260       0           4.0            259.0   \n",
       "49502    113  AP891021-0138       1           4.0            233.0   \n",
       "49503    113  AP891027-0195       0           4.0            226.0   \n",
       "49504    113  AP891102-0122       0           4.0            383.0   \n",
       "49505    113  AP891103-0147       0           4.0            123.0   \n",
       "49506    113  AP891103-0244       0           4.0            213.0   \n",
       "49507    113  AP891106-0189       1           4.0            443.0   \n",
       "49508    113  AP891107-0096       0           4.0            139.0   \n",
       "49509    113  AP891110-0008       0           4.0            233.0   \n",
       "49510    113  AP891111-0103       0           4.0            432.0   \n",
       "49511    113  AP891114-0116       0           4.0            564.0   \n",
       "49512    113  AP891114-0172       0           4.0            658.0   \n",
       "49513    113  AP891115-0047       0           4.0            461.0   \n",
       "49514    113  AP891118-0018       0           4.0            453.0   \n",
       "49515    113  AP891123-0016       0           4.0            211.0   \n",
       "49516    113  AP891129-0145       0           4.0            160.0   \n",
       "49517    113  AP891201-0039       0           4.0            235.0   \n",
       "49518    113  AP891202-0087       0           4.0            658.0   \n",
       "49519    113  AP891206-0060       0           4.0            168.0   \n",
       "49520    113  AP891207-0075       0           4.0            571.0   \n",
       "49521    113  AP891212-0026       0           4.0            280.0   \n",
       "49522    113  AP891212-0076       0           4.0            170.0   \n",
       "49523    113  AP891213-0173       0           4.0            506.0   \n",
       "49524    113  AP891214-0025       0           4.0            487.0   \n",
       "49525    113  AP891218-0021       0           4.0            172.0   \n",
       "\n",
       "       document unique      tfidf       bm25  jelinek mercer  dirichlet prior  \\\n",
       "0                296.0  24.020823  13.950561        3.216136         0.777933   \n",
       "1                245.0  23.671856  18.590453        9.689087         4.906967   \n",
       "2                219.0  35.006768  27.085821       16.471032         9.202167   \n",
       "3                201.0   0.000000   0.000000        0.000000         0.000000   \n",
       "4                130.0   0.000000   0.000000        0.000000         0.000000   \n",
       "5                171.0  43.604136  25.943141       11.048272         6.006798   \n",
       "6                201.0   0.000000   0.000000        0.000000         0.000000   \n",
       "7                236.0  13.595374  11.748166        2.368201         0.091057   \n",
       "8                226.0  33.587524  28.112019       15.916534         8.645984   \n",
       "9                145.0  45.292147  41.796820       14.713149         7.002916   \n",
       "10               150.0  26.229972  25.244887        9.963387         5.052747   \n",
       "11               231.0  36.655421  23.732055        9.978573         5.064910   \n",
       "12               211.0  24.020823  16.063962        3.607029         1.183174   \n",
       "13               188.0  31.505102  27.179685        7.081691         2.324797   \n",
       "14               263.0  26.923625  14.764672        3.557006         1.111895   \n",
       "15               318.0  38.468804  19.604005       10.722845         5.647920   \n",
       "16               200.0  30.039677  23.954588       11.064524         6.120394   \n",
       "17                89.0  24.020823  19.370401        4.425484         1.682966   \n",
       "18               144.0  25.895154  28.308417        6.950129         2.102079   \n",
       "19               230.0  30.910133  15.658844        4.065621         1.609314   \n",
       "20               101.0   0.000000   0.000000        0.000000         0.000000   \n",
       "21               158.0   0.000000   0.000000        0.000000         0.000000   \n",
       "22               190.0   0.000000   0.000000        0.000000         0.000000   \n",
       "23               308.0   0.000000   0.000000        0.000000         0.000000   \n",
       "24               354.0  24.020823  12.800212        3.021524         0.518863   \n",
       "25               232.0  19.963196  14.738112        3.122591         0.748700   \n",
       "26               246.0  57.252348  27.813724        9.085190         4.132236   \n",
       "27               248.0  67.592585  35.245179       14.943210         7.472491   \n",
       "28               118.0  13.595374  15.769942        3.041577         0.648024   \n",
       "29               435.0  33.586541  12.504489        3.683279         0.986592   \n",
       "...                ...        ...        ...             ...              ...   \n",
       "49496             41.0  33.637593  36.162298       12.237254         5.297046   \n",
       "49497            295.0  71.764075  35.213800       10.641305         4.378302   \n",
       "49498             63.0  15.487444  15.732500        6.223210         3.170443   \n",
       "49499            210.0  57.361585  40.919621       10.619763         4.576913   \n",
       "49500            206.0  50.038807  27.097001       11.040341         6.380163   \n",
       "49501            121.0  16.228950  19.071795        1.378891        -0.165378   \n",
       "49502            113.0  49.047187  50.307231       11.682494         4.841506   \n",
       "49503            119.0  51.662906  48.863225       11.834895         5.139858   \n",
       "49504            155.0  29.287975  21.216045        2.026155         0.108900   \n",
       "49505             61.0  36.523202  34.357447       11.668490         5.532387   \n",
       "49506             91.0  16.228950  20.871719        1.617424        -0.045888   \n",
       "49507            251.0  61.357772  44.494273       10.454415         4.160804   \n",
       "49508             63.0  32.818237  33.053758       11.271225         5.230081   \n",
       "49509            115.0  24.137315  22.280646        2.014322         0.104285   \n",
       "49510            181.0  43.581461  26.141627       10.094702         5.350156   \n",
       "49511            217.0  67.003091  42.411812       11.743638         5.627640   \n",
       "49512            238.0  66.910222  39.596638       11.267038         5.206848   \n",
       "49513            179.0  52.942934  27.991641       11.387931         6.642451   \n",
       "49514            189.0  44.715499  27.960607       10.435033         5.722464   \n",
       "49515             94.0  34.293268  30.642739       10.631747         5.230461   \n",
       "49516             73.0  38.516916  33.537278       11.660510         5.749566   \n",
       "49517            108.0  36.523202  31.500853       10.501033         5.213408   \n",
       "49518            260.0  70.932540  38.938908       11.859856         5.793138   \n",
       "49519             78.0  26.184483  17.879548        5.641419         2.742469   \n",
       "49520            199.0  67.665283  40.815332       11.757627         5.683002   \n",
       "49521            127.0  56.955552  50.719785       11.744874         4.862820   \n",
       "49522             71.0  51.633477  46.837914       17.832061         9.129729   \n",
       "49523            167.0  47.119802  31.216106        7.617506         3.548574   \n",
       "49524            202.0  64.721931  43.841140       10.852400         4.505996   \n",
       "49525             79.0  21.841799  14.721796        6.838255         3.991388   \n",
       "\n",
       "       absolute discounting  w2v: sum  w2v: avg  w2v: wmd       lsi       lda  \n",
       "0                 31.724555  0.039118  0.039118  1.133204  0.219277 -0.062410  \n",
       "1                 62.680648  0.078235  0.078235  2.266407  0.077448 -0.094482  \n",
       "2                 93.959587  0.117352  0.117352  3.399611  0.089082 -0.082875  \n",
       "3                  0.000000  0.000000  0.000000  0.000000  0.005009  0.023027  \n",
       "4                  0.000000  0.000000  0.000000  0.000000  0.106967 -0.038606  \n",
       "5                 61.030405  0.078235  0.078235  2.266407  0.441782 -0.062659  \n",
       "6                  0.000000  0.000000  0.000000  0.000000  0.046916 -0.049820  \n",
       "7                 27.773922  0.039117  0.039117  1.133204  0.137957 -0.033829  \n",
       "8                 93.301055  0.117352  0.117352  3.399611  0.108973 -0.014807  \n",
       "9                 85.436913  0.117353  0.117353  3.399611  0.261607  0.024155  \n",
       "10                57.985625  0.078235  0.078235  2.266407  0.118421 -0.015223  \n",
       "11                64.484407  0.078235  0.078235  2.266407  0.180224 -0.059052  \n",
       "12                30.370550  0.039117  0.039117  1.133204  0.230948  0.023751  \n",
       "13                57.376964  0.078235  0.078235  2.266407  0.114459 -0.079686  \n",
       "14                31.641198  0.039118  0.039118  1.133204  0.257056 -0.050479  \n",
       "15                68.847608  0.078236  0.078236  2.266407  0.165437 -0.035594  \n",
       "16                63.455016  0.078235  0.078235  2.266407  0.164298 -0.034000  \n",
       "17                26.917663  0.039118  0.039118  1.133204  0.378700 -0.033502  \n",
       "18                52.846040  0.078235  0.078235  2.266407  0.158616 -0.055196  \n",
       "19                31.602738  0.039117  0.039117  1.133204  0.329308 -0.055557  \n",
       "20                 0.000000  0.000000  0.000000  0.000000  0.064111 -0.012897  \n",
       "21                 0.000000  0.000000  0.000000  0.000000  0.023471 -0.006151  \n",
       "22                 0.000000  0.000000  0.000000  0.000000  0.023259 -0.016838  \n",
       "23                 0.000000  0.000000  0.000000  0.000000  0.036204 -0.005327  \n",
       "24                32.440305  0.039118  0.039118  1.133204  0.150489 -0.056878  \n",
       "25                30.103440  0.039117  0.039117  1.133204  0.130421 -0.023533  \n",
       "26                64.958622  0.078235  0.078235  2.266407  0.224348 -0.047750  \n",
       "27                96.808983  0.117353  0.117353  3.399611  0.242720 -0.051928  \n",
       "28                25.001333  0.039118  0.039118  1.133204  0.133109 -0.045196  \n",
       "29                34.482659  0.039118  0.039118  1.133204  0.269300 -0.013641  \n",
       "...                     ...       ...       ...       ...       ...       ...  \n",
       "49496             41.184266 -0.005110 -0.005110  2.121832  0.336184 -0.035296  \n",
       "49497             77.110509 -0.007666 -0.007665  3.182748  0.472326 -0.051060  \n",
       "49498             22.539682 -0.002555 -0.002555  1.060916  0.025667 -0.038076  \n",
       "49499             72.458072 -0.007666 -0.007666  3.182748  0.233094 -0.039196  \n",
       "49500             54.019147 -0.005110 -0.005110  2.121832  0.428973 -0.056378  \n",
       "49501             18.284711 -0.002555 -0.002555  1.060916  0.105895 -0.132754  \n",
       "49502             63.984861 -0.007666 -0.007666  3.182748  0.368340 -0.031285  \n",
       "49503             64.948320 -0.007666 -0.007666  3.182748  0.355992 -0.004944  \n",
       "49504             22.072138 -0.002555 -0.002555  1.060916  0.279663  0.002111  \n",
       "49505             44.214704 -0.005110 -0.005110  2.121832  0.306970 -0.046754  \n",
       "49506             17.429918 -0.002555 -0.002555  1.060916  0.123349 -0.074943  \n",
       "49507             75.573772 -0.007666 -0.007666  3.182748  0.290200 -0.141253  \n",
       "49508             42.399839 -0.005110 -0.005110  2.121832  0.311952 -0.016285  \n",
       "49509             20.530031 -0.002555 -0.002555  1.060916  0.247593 -0.068702  \n",
       "49510             50.007556 -0.005110 -0.005111  2.121832  0.485381 -0.188554  \n",
       "49511             74.247905 -0.007666 -0.007666  3.182748  0.491776 -0.052499  \n",
       "49512             75.118470 -0.007666 -0.007666  3.182748  0.489864 -0.062305  \n",
       "49513             53.425864 -0.005110 -0.005110  2.121832  0.468551 -0.042159  \n",
       "49514             52.533873 -0.005110 -0.005110  2.121832  0.356342 -0.055172  \n",
       "49515             45.080384 -0.005111 -0.005111  2.121832  0.295204 -0.057757  \n",
       "49516             45.681682 -0.005110 -0.005110  2.121832  0.317193 -0.057658  \n",
       "49517             47.642248 -0.005111 -0.005111  2.121832  0.372028 -0.032474  \n",
       "49518             76.672251 -0.007666 -0.007666  3.182748  0.466252 -0.072006  \n",
       "49519             23.178359 -0.002555 -0.002555  1.060916  0.477938 -0.110388  \n",
       "49520             73.752148 -0.007666 -0.007666  3.182748  0.354611 -0.021904  \n",
       "49521             67.433949 -0.007666 -0.007666  3.182748  0.384218 -0.007835  \n",
       "49522             67.095717 -0.007666 -0.007666  3.182748  0.301389  0.002757  \n",
       "49523             48.647406 -0.005110 -0.005110  2.121832  0.145526 -0.097167  \n",
       "49524             72.755140 -0.007666 -0.007666  3.182748  0.276304 -0.081359  \n",
       "49525             24.534298 -0.002555 -0.002555  1.060916  0.185604  0.018077  \n",
       "\n",
       "[49526 rows x 16 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.to_csv('trainData.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "regression = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load CSV and drop columns\n",
    "trainData = pd.read_csv('trainData.csv', delimiter=',')\n",
    "trainData = trainData.drop(columns=['Unnamed: 0'])\n",
    "trainData = trainData.drop(columns=['query'])\n",
    "trainData = trainData.drop(columns=['doc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46722463"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id = int(extDocId2id['AP880312-0116'])\n",
    "\n",
    "# Q = []\n",
    "# for query_term_id in tokenized_queries['68']: #for each word_id in query\n",
    "#     term = dictionary[query_term_id]\n",
    "#     Q.append(model[term])\n",
    "\n",
    "# Q = np.array(Q)\n",
    "# vector = Q.sum(axis=0) \n",
    "# query_Test = vector / np.sqrt((vector ** 2).sum())\n",
    "    \n",
    "    \n",
    "# ext_doc_id, doc_token_ids = index.document(int_doc_id)\n",
    "\n",
    "# D = []\n",
    "# for token_id in doc_token_ids: \n",
    "#     if token_id > 0:\n",
    "#         term = dictionary[query_term_id]\n",
    "#         D.append(model[term])\n",
    "# D = np.array(D)\n",
    "# vector = D.sum(axis=0) \n",
    "# doc_Test = vector / np.sqrt((vector ** 2).sum())\n",
    "\n",
    "\n",
    "# cosine_similarity = np.dot(query_Test, doc_Test)/(np.linalg.norm(query_Test)* np.linalg.norm(doc_Test))\n",
    "# cosine_similarity\n",
    "\n",
    "    \n",
    "# # from sklearn.metrics.pairwise import cosine_distances\n",
    "# # cosine_distances(list(query_Test), list(doc_Test))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n"
     ]
    }
   ],
   "source": [
    "trainDataVars = trainData.columns.values.tolist()\n",
    "y = ['result']\n",
    "X = [i for i in trainDataVars if i not in y]\n",
    "\n",
    "rfe = RFE(regression, 18)\n",
    "rfe = rfe.fit(trainData[X], trainData[y].values.ravel())\n",
    "print(rfe.support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single split logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.74702\n"
     ]
    }
   ],
   "source": [
    "X = trainData[[\n",
    "    'query length', \n",
    "    'document length', \n",
    "    'document unique', \n",
    "    'tfidf', \n",
    "    'bm25', \n",
    "    'jelinek mercer', \n",
    "    'dirichlet prior', \n",
    "    'absolute discounting', \n",
    "    'w2v: sum', \n",
    "    'w2v: avg', \n",
    "    'w2v: wmd',\n",
    "    'lsi',\n",
    "    'lda'\n",
    "]]\n",
    "y = trainData['result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "regression.fit(X_train, y_train)\n",
    "y_pred = regression.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.5f}'.format(regression.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 fold crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation average accuracy: 0.73889\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=10, random_state=100)\n",
    "\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(regression, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(\"10-fold cross validation average accuracy: %.5f\" % (results.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision, Recall and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.98      0.85      7299\n",
      "          1       0.62      0.10      0.17      2607\n",
      "\n",
      "avg / total       0.72      0.75      0.67      9906\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_final_retrieval(model_name, **args):\n",
    "\n",
    "    run_out_path = '{}.run'.format(model_name)\n",
    "\n",
    "    if os.path.exists(run_out_path):\n",
    "        return\n",
    "\n",
    "    retrieval_start_time = time.time()\n",
    "\n",
    "    print('Retrieving using ltr')\n",
    "\n",
    "    trainData = pd.read_csv('trainData.csv', delimiter=',')\n",
    "    trainData = trainData.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    # for qid in tokenized_queries: \n",
    "\n",
    "    for idx, row in trainData.iterrows():\n",
    "\n",
    "        ext_doc = str(trainData.iloc[idx]['doc'])\n",
    "        query = str(trainData.iloc[idx]['query'])\n",
    "\n",
    "        inputDf = trainData[idx: idx + 1]\n",
    "        inputDf = inputDf.drop(columns=['query', 'doc', 'result'])\n",
    "\n",
    "        score = regression.predict_proba(inputDf)    \n",
    "\n",
    "        if query in data:\n",
    "            data[query].append((score[0][1], ext_doc))\n",
    "        else:\n",
    "            data[query] = []\n",
    "            data[query].append((score[0][1], ext_doc))\n",
    "\n",
    "    #     write out\n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name=model_name,\n",
    "            data=data,\n",
    "            out_f=f_out,\n",
    "\n",
    "            max_objects_per_query=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving using ltr\n",
      "elapsed time: 73.25730466842651\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "run_final_retrieval('retrievals/ltr')\n",
    "\n",
    "print ('elapsed time:',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_5                   \tall\t0.4800\r\n",
      "recall_1000           \tall\t0.9883\r\n",
      "ndcg_cut_10           \tall\t0.4660\r\n",
      "map_cut_1000          \tall\t0.3994\r\n"
     ]
    }
   ],
   "source": [
    "# trec_eval command for test of averaged vectors\n",
    "!trec_eval -m all_trec ./ap_88_89/qrel_test retrievals/ltr.run | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4322dc6588>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f431c8f74a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_scoring = pd.DataFrame()\n",
    "\n",
    "results = !trec_eval -m all_trec -q ./ap_88_89/qrel_test retrievals/ltr.run | grep -E \"^ndcg_cut_10\\s\"\n",
    "\n",
    "for result in results:\n",
    "    result = re.sub( '\\s+', ' ', result ).strip().split()\n",
    "\n",
    "    idx = result[1]\n",
    "    value = float(result[2])\n",
    "\n",
    "    final_scoring.set_value(idx, 1, value)\n",
    "    \n",
    "final_scoring.plot(kind='bar', figsize=(15, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "1000\n",
      "186\n",
      "1000\n",
      "56\n",
      "1000\n",
      "174\n",
      "1000\n",
      "104\n",
      "1000\n",
      "159\n",
      "1000\n",
      "171\n",
      "1000\n",
      "165\n",
      "1000\n",
      "103\n",
      "1000\n",
      "148\n",
      "1000\n",
      "52\n",
      "1000\n",
      "185\n",
      "1000\n",
      "127\n",
      "1000\n",
      "74\n",
      "1000\n",
      "60\n",
      "1000\n",
      "158\n",
      "1000\n",
      "113\n",
      "1000\n",
      "136\n",
      "1000\n",
      "194\n",
      "1000\n",
      "68\n",
      "1000\n",
      "65\n",
      "1000\n",
      "160\n",
      "1000\n",
      "72\n",
      "1000\n",
      "157\n",
      "1000\n",
      "144\n",
      "1000\n",
      "162\n",
      "1000\n",
      "170\n",
      "1000\n",
      "128\n",
      "1000\n",
      "133\n",
      "1000\n",
      "187\n",
      "1000\n",
      "183\n",
      "1000\n",
      "92\n",
      "1000\n",
      "154\n",
      "1000\n",
      "132\n",
      "1000\n",
      "101\n",
      "1000\n",
      "70\n",
      "288\n",
      "78\n",
      "253\n",
      "179\n",
      "1000\n",
      "184\n",
      "1000\n",
      "76\n",
      "1000\n",
      "59\n",
      "1000\n",
      "124\n",
      "1000\n",
      "98\n",
      "1000\n",
      "120\n",
      "1000\n",
      "91\n",
      "1000\n",
      "102\n",
      "1000\n",
      "138\n",
      "1000\n",
      "63\n",
      "1000\n",
      "140\n",
      "1000\n",
      "75\n",
      "161\n",
      "147\n",
      "1000\n",
      "150\n",
      "1000\n",
      "143\n",
      "1000\n",
      "137\n",
      "1000\n",
      "193\n",
      "1000\n",
      "166\n",
      "1000\n",
      "61\n",
      "1000\n",
      "58\n",
      "1000\n",
      "129\n",
      "1000\n",
      "79\n",
      "1000\n",
      "190\n",
      "1000\n",
      "164\n",
      "1000\n",
      "107\n",
      "1000\n",
      "85\n",
      "1000\n",
      "169\n",
      "1000\n",
      "192\n",
      "1000\n",
      "57\n",
      "157\n",
      "175\n",
      "1000\n",
      "195\n",
      "1000\n",
      "178\n",
      "1000\n",
      "167\n",
      "1000\n",
      "200\n",
      "1000\n",
      "155\n",
      "1000\n",
      "153\n",
      "1000\n",
      "139\n",
      "1000\n",
      "83\n",
      "1000\n",
      "95\n",
      "1000\n",
      "149\n",
      "1000\n",
      "105\n",
      "1000\n",
      "130\n",
      "1000\n",
      "67\n",
      "1000\n",
      "81\n",
      "1000\n",
      "172\n",
      "1000\n",
      "176\n",
      "1000\n",
      "51\n",
      "1000\n",
      "84\n",
      "1000\n",
      "96\n",
      "1000\n",
      "168\n",
      "1000\n",
      "119\n",
      "1000\n",
      "99\n",
      "1000\n",
      "134\n",
      "1000\n",
      "182\n",
      "1000\n",
      "142\n",
      "1000\n",
      "108\n",
      "1000\n",
      "123\n",
      "1000\n",
      "93\n",
      "1000\n",
      "173\n",
      "1000\n",
      "151\n",
      "1000\n",
      "116\n",
      "1000\n",
      "118\n",
      "1000\n",
      "146\n",
      "1000\n",
      "87\n",
      "1000\n",
      "117\n",
      "1000\n",
      "125\n",
      "1000\n",
      "180\n",
      "1000\n",
      "100\n",
      "1000\n",
      "112\n",
      "1000\n",
      "197\n",
      "1000\n",
      "189\n",
      "1000\n",
      "73\n",
      "1000\n",
      "109\n",
      "1000\n",
      "69\n",
      "1000\n",
      "121\n",
      "1000\n",
      "90\n",
      "1000\n",
      "156\n",
      "1000\n",
      "196\n",
      "1000\n",
      "110\n",
      "1000\n",
      "62\n",
      "1000\n",
      "97\n",
      "1000\n",
      "177\n",
      "1000\n",
      "82\n",
      "1000\n",
      "86\n",
      "1000\n",
      "188\n",
      "689\n",
      "64\n",
      "1000\n",
      "152\n",
      "1000\n",
      "88\n",
      "1000\n",
      "135\n",
      "1000\n",
      "131\n",
      "1000\n",
      "145\n",
      "1000\n",
      "115\n",
      "1000\n",
      "141\n",
      "1000\n",
      "191\n",
      "1000\n",
      "77\n",
      "133\n",
      "53\n",
      "1000\n",
      "89\n",
      "1000\n",
      "126\n",
      "1000\n",
      "163\n",
      "1000\n",
      "199\n",
      "1000\n",
      "106\n",
      "1000\n",
      "80\n",
      "1000\n",
      "54\n",
      "1000\n",
      "114\n",
      "1000\n",
      "181\n",
      "1000\n",
      "122\n",
      "1000\n",
      "66\n",
      "1000\n",
      "161\n",
      "1000\n",
      "71\n",
      "1000\n",
      "198\n",
      "1000\n",
      "94\n",
      "1000\n",
      "55\n",
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145651</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145652</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145653</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145654</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145655</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145656</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145657</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145658</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145659</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145660</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145661</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145662</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145663</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145664</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145665</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145666</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145667</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145668</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145669</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145670</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145671</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145672</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145673</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145674</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145675</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145676</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145677</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145678</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145679</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145680</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145681 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  doc query\n",
       "0       AP890425-0111   111\n",
       "1       AP890425-0111   111\n",
       "2       AP890425-0111   111\n",
       "3       AP890425-0111   111\n",
       "4       AP890425-0111   111\n",
       "5       AP890425-0111   111\n",
       "6       AP890425-0111   111\n",
       "7       AP890425-0111   111\n",
       "8       AP890425-0111   111\n",
       "9       AP890425-0111   111\n",
       "10      AP890425-0111   111\n",
       "11      AP890425-0111   111\n",
       "12      AP890425-0111   111\n",
       "13      AP890425-0111   111\n",
       "14      AP890425-0111   111\n",
       "15      AP890425-0111   111\n",
       "16      AP890425-0111   111\n",
       "17      AP890425-0111   111\n",
       "18      AP890425-0111   111\n",
       "19      AP890425-0111   111\n",
       "20      AP890425-0111   111\n",
       "21      AP890425-0111   111\n",
       "22      AP890425-0111   111\n",
       "23      AP890425-0111   111\n",
       "24      AP890425-0111   111\n",
       "25      AP890425-0111   111\n",
       "26      AP890425-0111   111\n",
       "27      AP890425-0111   111\n",
       "28      AP890425-0111   111\n",
       "29      AP890425-0111   111\n",
       "...               ...   ...\n",
       "145651  AP890425-0055    55\n",
       "145652  AP890425-0055    55\n",
       "145653  AP890425-0055    55\n",
       "145654  AP890425-0055    55\n",
       "145655  AP890425-0055    55\n",
       "145656  AP890425-0055    55\n",
       "145657  AP890425-0055    55\n",
       "145658  AP890425-0055    55\n",
       "145659  AP890425-0055    55\n",
       "145660  AP890425-0055    55\n",
       "145661  AP890425-0055    55\n",
       "145662  AP890425-0055    55\n",
       "145663  AP890425-0055    55\n",
       "145664  AP890425-0055    55\n",
       "145665  AP890425-0055    55\n",
       "145666  AP890425-0055    55\n",
       "145667  AP890425-0055    55\n",
       "145668  AP890425-0055    55\n",
       "145669  AP890425-0055    55\n",
       "145670  AP890425-0055    55\n",
       "145671  AP890425-0055    55\n",
       "145672  AP890425-0055    55\n",
       "145673  AP890425-0055    55\n",
       "145674  AP890425-0055    55\n",
       "145675  AP890425-0055    55\n",
       "145676  AP890425-0055    55\n",
       "145677  AP890425-0055    55\n",
       "145678  AP890425-0055    55\n",
       "145679  AP890425-0055    55\n",
       "145680  AP890425-0055    55\n",
       "\n",
       "[145681 rows x 2 columns]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalData = pd.DataFrame()\n",
    "\n",
    "for query in tokenized_queries:\n",
    "    print(query)\n",
    "    print(len(tfidf_rank[query]))    \n",
    "    for document in tfidf_rank[query]:\n",
    "        doc = index.document(int(query))[0]\n",
    "        evalData = evalData.append({'query': query, 'doc': doc}, ignore_index=True)\n",
    "    \n",
    "evalData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query length\n",
    "for idx, row in evalData.iterrows():\n",
    "    \n",
    "    score = len(tokenized_queries[str(evalData.iloc[idx]['query'])])\n",
    "    evalData.at[idx, 'query length'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dcoument length\n",
    "for idx, row in evalData.iterrows():\n",
    "    \n",
    "    doc_id = extDocId2id[evalData.iloc[idx]['doc']]\n",
    "    score = len(index.document(doc_id)[1])\n",
    "    evalData.at[idx, 'document length'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unique word in doc\n",
    "for idx, row in evalData.iterrows():\n",
    "    \n",
    "    doc_id = extDocId2id[evalData.iloc[idx]['doc']]\n",
    "    score = unique_terms_per_document[doc_id]\n",
    "    evalData.at[idx, 'document unique'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append TF-IDF data\n",
    "for idx, row in evalData.iterrows():\n",
    "\n",
    "    score = run_ltr_retrieval(tfidf, evalData.iloc[idx]['doc'], evalData.iloc[idx]['query'])\n",
    "    evalData.at[idx, 'tfidf'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append BM25 data\n",
    "for idx, row in evalData.iterrows():\n",
    "\n",
    "    score = run_ltr_retrieval(bm25, evalData.iloc[idx]['doc'], evalData.iloc[idx]['query'])\n",
    "    evalData.at[idx, 'bm25'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append Jelinek Mercer data\n",
    "for idx, row in evalData.iterrows():\n",
    "\n",
    "    score = run_ltr_retrieval(jelinek_mercer, evalData.iloc[idx]['doc'], evalData.iloc[idx]['query'])\n",
    "    evalData.at[idx, 'jelinek mercer'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append Dirichlet Prior data\n",
    "for idx, row in evalData.iterrows():\n",
    "\n",
    "    score = run_ltr_retrieval(dirichlet_prior, evalData.iloc[idx]['doc'], evalData.iloc[idx]['query'])\n",
    "    evalData.at[idx, 'dirichlet prior'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append Absolute Discounting data\n",
    "for idx, row in evalData.iterrows():\n",
    "\n",
    "    score = run_ltr_retrieval(absolute_discounting, evalData.iloc[idx]['doc'], evalData.iloc[idx]['query'])\n",
    "    evalData.at[idx, 'absolute discounting'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append Word2Vec Sum data\n",
    "for idx, row in evalData.iterrows():\n",
    "\n",
    "    score = run_ltr_retrieval(summed_vectors, evalData.iloc[idx]['doc'], evalData.iloc[idx]['query'])\n",
    "    evalData.at[idx, 'w2v: sum'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append Word2Vec Average data\n",
    "for idx, row in evalData.iterrows():\n",
    "\n",
    "    score = run_ltr_retrieval(averaged_vectors, evalData.iloc[idx]['doc'], evalData.iloc[idx]['query'])\n",
    "    evalData.at[idx, 'w2v: avg'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append Word2Vec WMD data\n",
    "for idx, row in evalData.iterrows():\n",
    "\n",
    "    score = run_ltr_retrieval(wmd_vectors, evalData.iloc[idx]['doc'], evalData.iloc[idx]['query'])\n",
    "    evalData.at[idx, 'w2v: wmd'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append LSI data\n",
    "for idx, row in evalData.iterrows():    \n",
    "        \n",
    "    external_id = extDocId2id[str(evalData.iloc[idx]['doc'])]\n",
    "\n",
    "    score = gensim_rank_pair(external_id, str(evalData.iloc[idx]['query']), lsi, transformed_queries)\n",
    "    evalData.at[idx, 'lsi'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append LDA data\n",
    "for idx, row in evalData.iterrows():    \n",
    "        \n",
    "    external_id = extDocId2id[str(evalData.iloc[idx]['doc'])]\n",
    "\n",
    "    score = gensim_rank_pair(external_id, str(evalData.iloc[idx]['query']), lda, transformed_queries)\n",
    "    evalData.at[idx, 'lda'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>query</th>\n",
       "      <th>query length</th>\n",
       "      <th>document length</th>\n",
       "      <th>document unique</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>bm25</th>\n",
       "      <th>jelinek mercer</th>\n",
       "      <th>dirichlet prior</th>\n",
       "      <th>absolute discounting</th>\n",
       "      <th>w2v: sum</th>\n",
       "      <th>w2v: avg</th>\n",
       "      <th>w2v: wmd</th>\n",
       "      <th>lsi</th>\n",
       "      <th>lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AP890425-0111</td>\n",
       "      <td>111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.064308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145651</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145652</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145653</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145654</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145655</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.009640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145656</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145657</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.009622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145658</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145659</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.009547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145660</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.009505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145661</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145662</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145663</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145664</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.009481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145665</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145666</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145667</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145668</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145669</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145670</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.009651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145671</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.009674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145672</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.009522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145673</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.009674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145674</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.009667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145675</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145676</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.009683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145677</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145678</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.009390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145679</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145680</th>\n",
       "      <td>AP890425-0055</td>\n",
       "      <td>55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024580</td>\n",
       "      <td>-0.002819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145681 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  doc query  query length  document length  document unique  \\\n",
       "0       AP890425-0111   111           2.0            568.0            221.0   \n",
       "1       AP890425-0111   111           2.0            568.0            221.0   \n",
       "2       AP890425-0111   111           2.0            568.0            221.0   \n",
       "3       AP890425-0111   111           2.0            568.0            221.0   \n",
       "4       AP890425-0111   111           2.0            568.0            221.0   \n",
       "5       AP890425-0111   111           2.0            568.0            221.0   \n",
       "6       AP890425-0111   111           2.0            568.0            221.0   \n",
       "7       AP890425-0111   111           2.0            568.0            221.0   \n",
       "8       AP890425-0111   111           2.0            568.0            221.0   \n",
       "9       AP890425-0111   111           2.0            568.0            221.0   \n",
       "10      AP890425-0111   111           2.0            568.0            221.0   \n",
       "11      AP890425-0111   111           2.0            568.0            221.0   \n",
       "12      AP890425-0111   111           2.0            568.0            221.0   \n",
       "13      AP890425-0111   111           2.0            568.0            221.0   \n",
       "14      AP890425-0111   111           2.0            568.0            221.0   \n",
       "15      AP890425-0111   111           2.0            568.0            221.0   \n",
       "16      AP890425-0111   111           2.0            568.0            221.0   \n",
       "17      AP890425-0111   111           2.0            568.0            221.0   \n",
       "18      AP890425-0111   111           2.0            568.0            221.0   \n",
       "19      AP890425-0111   111           2.0            568.0            221.0   \n",
       "20      AP890425-0111   111           2.0            568.0            221.0   \n",
       "21      AP890425-0111   111           2.0            568.0            221.0   \n",
       "22      AP890425-0111   111           2.0            568.0            221.0   \n",
       "23      AP890425-0111   111           2.0            568.0            221.0   \n",
       "24      AP890425-0111   111           2.0            568.0            221.0   \n",
       "25      AP890425-0111   111           2.0            568.0            221.0   \n",
       "26      AP890425-0111   111           2.0            568.0            221.0   \n",
       "27      AP890425-0111   111           2.0            568.0            221.0   \n",
       "28      AP890425-0111   111           2.0            568.0            221.0   \n",
       "29      AP890425-0111   111           2.0            568.0            221.0   \n",
       "...               ...   ...           ...              ...              ...   \n",
       "145651  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145652  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145653  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145654  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145655  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145656  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145657  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145658  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145659  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145660  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145661  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145662  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145663  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145664  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145665  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145666  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145667  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145668  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145669  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145670  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145671  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145672  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145673  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145674  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145675  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145676  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145677  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145678  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145679  AP890425-0055    55           2.0            438.0            177.0   \n",
       "145680  AP890425-0055    55           2.0            438.0            177.0   \n",
       "\n",
       "        tfidf  bm25  jelinek mercer  dirichlet prior  absolute discounting  \\\n",
       "0         0.0   0.0             0.0              0.0                   0.0   \n",
       "1         0.0   0.0             0.0              0.0                   0.0   \n",
       "2         0.0   0.0             0.0              0.0                   0.0   \n",
       "3         0.0   0.0             0.0              0.0                   0.0   \n",
       "4         0.0   0.0             0.0              0.0                   0.0   \n",
       "5         0.0   0.0             0.0              0.0                   0.0   \n",
       "6         0.0   0.0             0.0              0.0                   0.0   \n",
       "7         0.0   0.0             0.0              0.0                   0.0   \n",
       "8         0.0   0.0             0.0              0.0                   0.0   \n",
       "9         0.0   0.0             0.0              0.0                   0.0   \n",
       "10        0.0   0.0             0.0              0.0                   0.0   \n",
       "11        0.0   0.0             0.0              0.0                   0.0   \n",
       "12        0.0   0.0             0.0              0.0                   0.0   \n",
       "13        0.0   0.0             0.0              0.0                   0.0   \n",
       "14        0.0   0.0             0.0              0.0                   0.0   \n",
       "15        0.0   0.0             0.0              0.0                   0.0   \n",
       "16        0.0   0.0             0.0              0.0                   0.0   \n",
       "17        0.0   0.0             0.0              0.0                   0.0   \n",
       "18        0.0   0.0             0.0              0.0                   0.0   \n",
       "19        0.0   0.0             0.0              0.0                   0.0   \n",
       "20        0.0   0.0             0.0              0.0                   0.0   \n",
       "21        0.0   0.0             0.0              0.0                   0.0   \n",
       "22        0.0   0.0             0.0              0.0                   0.0   \n",
       "23        0.0   0.0             0.0              0.0                   0.0   \n",
       "24        0.0   0.0             0.0              0.0                   0.0   \n",
       "25        0.0   0.0             0.0              0.0                   0.0   \n",
       "26        0.0   0.0             0.0              0.0                   0.0   \n",
       "27        0.0   0.0             0.0              0.0                   0.0   \n",
       "28        0.0   0.0             0.0              0.0                   0.0   \n",
       "29        0.0   0.0             0.0              0.0                   0.0   \n",
       "...       ...   ...             ...              ...                   ...   \n",
       "145651    0.0   0.0             0.0              0.0                   0.0   \n",
       "145652    0.0   0.0             0.0              0.0                   0.0   \n",
       "145653    0.0   0.0             0.0              0.0                   0.0   \n",
       "145654    0.0   0.0             0.0              0.0                   0.0   \n",
       "145655    0.0   0.0             0.0              0.0                   0.0   \n",
       "145656    0.0   0.0             0.0              0.0                   0.0   \n",
       "145657    0.0   0.0             0.0              0.0                   0.0   \n",
       "145658    0.0   0.0             0.0              0.0                   0.0   \n",
       "145659    0.0   0.0             0.0              0.0                   0.0   \n",
       "145660    0.0   0.0             0.0              0.0                   0.0   \n",
       "145661    0.0   0.0             0.0              0.0                   0.0   \n",
       "145662    0.0   0.0             0.0              0.0                   0.0   \n",
       "145663    0.0   0.0             0.0              0.0                   0.0   \n",
       "145664    0.0   0.0             0.0              0.0                   0.0   \n",
       "145665    0.0   0.0             0.0              0.0                   0.0   \n",
       "145666    0.0   0.0             0.0              0.0                   0.0   \n",
       "145667    0.0   0.0             0.0              0.0                   0.0   \n",
       "145668    0.0   0.0             0.0              0.0                   0.0   \n",
       "145669    0.0   0.0             0.0              0.0                   0.0   \n",
       "145670    0.0   0.0             0.0              0.0                   0.0   \n",
       "145671    0.0   0.0             0.0              0.0                   0.0   \n",
       "145672    0.0   0.0             0.0              0.0                   0.0   \n",
       "145673    0.0   0.0             0.0              0.0                   0.0   \n",
       "145674    0.0   0.0             0.0              0.0                   0.0   \n",
       "145675    0.0   0.0             0.0              0.0                   0.0   \n",
       "145676    0.0   0.0             0.0              0.0                   0.0   \n",
       "145677    0.0   0.0             0.0              0.0                   0.0   \n",
       "145678    0.0   0.0             0.0              0.0                   0.0   \n",
       "145679    0.0   0.0             0.0              0.0                   0.0   \n",
       "145680    0.0   0.0             0.0              0.0                   0.0   \n",
       "\n",
       "        w2v: sum  w2v: avg  w2v: wmd       lsi       lda  \n",
       "0            0.0       0.0       0.0  0.003639  0.064326  \n",
       "1            0.0       0.0       0.0  0.003639  0.064338  \n",
       "2            0.0       0.0       0.0  0.003639  0.064320  \n",
       "3            0.0       0.0       0.0  0.003639  0.064300  \n",
       "4            0.0       0.0       0.0  0.003639  0.064304  \n",
       "5            0.0       0.0       0.0  0.003639  0.064323  \n",
       "6            0.0       0.0       0.0  0.003639  0.064334  \n",
       "7            0.0       0.0       0.0  0.003639  0.064323  \n",
       "8            0.0       0.0       0.0  0.003639  0.064318  \n",
       "9            0.0       0.0       0.0  0.003639  0.064315  \n",
       "10           0.0       0.0       0.0  0.003639  0.064348  \n",
       "11           0.0       0.0       0.0  0.003639  0.064356  \n",
       "12           0.0       0.0       0.0  0.003639  0.064319  \n",
       "13           0.0       0.0       0.0  0.003639  0.064322  \n",
       "14           0.0       0.0       0.0  0.003639  0.064307  \n",
       "15           0.0       0.0       0.0  0.003639  0.064315  \n",
       "16           0.0       0.0       0.0  0.003639  0.064342  \n",
       "17           0.0       0.0       0.0  0.003639  0.064303  \n",
       "18           0.0       0.0       0.0  0.003639  0.064323  \n",
       "19           0.0       0.0       0.0  0.003639  0.064325  \n",
       "20           0.0       0.0       0.0  0.003639  0.064301  \n",
       "21           0.0       0.0       0.0  0.003639  0.064316  \n",
       "22           0.0       0.0       0.0  0.003639  0.064319  \n",
       "23           0.0       0.0       0.0  0.003639  0.064315  \n",
       "24           0.0       0.0       0.0  0.003639  0.064349  \n",
       "25           0.0       0.0       0.0  0.003639  0.064337  \n",
       "26           0.0       0.0       0.0  0.003639  0.064322  \n",
       "27           0.0       0.0       0.0  0.003639  0.064357  \n",
       "28           0.0       0.0       0.0  0.003639  0.064348  \n",
       "29           0.0       0.0       0.0  0.003639  0.064308  \n",
       "...          ...       ...       ...       ...       ...  \n",
       "145651       0.0       0.0       0.0  0.024580 -0.002816  \n",
       "145652       0.0       0.0       0.0  0.024580 -0.002846  \n",
       "145653       0.0       0.0       0.0  0.024580 -0.002877  \n",
       "145654       0.0       0.0       0.0  0.024580 -0.002927  \n",
       "145655       0.0       0.0       0.0  0.024580 -0.009640  \n",
       "145656       0.0       0.0       0.0  0.024580 -0.002809  \n",
       "145657       0.0       0.0       0.0  0.024580 -0.009622  \n",
       "145658       0.0       0.0       0.0  0.024580 -0.002902  \n",
       "145659       0.0       0.0       0.0  0.024580 -0.009547  \n",
       "145660       0.0       0.0       0.0  0.024580 -0.009505  \n",
       "145661       0.0       0.0       0.0  0.024580 -0.002998  \n",
       "145662       0.0       0.0       0.0  0.024580 -0.002997  \n",
       "145663       0.0       0.0       0.0  0.024580 -0.002852  \n",
       "145664       0.0       0.0       0.0  0.024580 -0.009481  \n",
       "145665       0.0       0.0       0.0  0.024580 -0.002816  \n",
       "145666       0.0       0.0       0.0  0.024580 -0.002867  \n",
       "145667       0.0       0.0       0.0  0.024580 -0.002954  \n",
       "145668       0.0       0.0       0.0  0.024580 -0.002954  \n",
       "145669       0.0       0.0       0.0  0.024580 -0.002747  \n",
       "145670       0.0       0.0       0.0  0.024580 -0.009651  \n",
       "145671       0.0       0.0       0.0  0.024580 -0.009674  \n",
       "145672       0.0       0.0       0.0  0.024580 -0.009522  \n",
       "145673       0.0       0.0       0.0  0.024580 -0.009674  \n",
       "145674       0.0       0.0       0.0  0.024580 -0.009667  \n",
       "145675       0.0       0.0       0.0  0.024580 -0.002892  \n",
       "145676       0.0       0.0       0.0  0.024580 -0.009683  \n",
       "145677       0.0       0.0       0.0  0.024580 -0.002822  \n",
       "145678       0.0       0.0       0.0  0.024580 -0.009390  \n",
       "145679       0.0       0.0       0.0  0.024580 -0.002840  \n",
       "145680       0.0       0.0       0.0  0.024580 -0.002819  \n",
       "\n",
       "[145681 rows x 15 columns]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalData.to_csv('evalData.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read existing data for quick updating\n",
    "evalData = pd.read_csv('evalData.csv', delimiter=',')\n",
    "evalData = trainData.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_1000_retrieval(model_name, **args):\n",
    "\n",
    "    run_out_path = '{}.run'.format(model_name)\n",
    "\n",
    "    if os.path.exists(run_out_path):\n",
    "        return\n",
    "\n",
    "    retrieval_start_time = time.time()\n",
    "\n",
    "    print('Retrieving using ltr')\n",
    "\n",
    "    evalData = pd.read_csv('trainData.csv', delimiter=',')\n",
    "    evalData = trainData.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    # for qid in tokenized_queries: \n",
    "\n",
    "    for idx, row in evalData.iterrows():\n",
    "\n",
    "        ext_doc = str(evalData.iloc[idx]['doc'])\n",
    "        query = str(evalData.iloc[idx]['query'])\n",
    "\n",
    "        inputDf = evalData[idx: idx + 1]\n",
    "        inputDf = inputDf.drop(columns=['query', 'doc', 'result'])\n",
    "\n",
    "        score = regression.predict_proba(inputDf)    \n",
    "\n",
    "        if query in data:\n",
    "            data[query].append((score[0][1], ext_doc))\n",
    "        else:\n",
    "            data[query] = []\n",
    "            data[query].append((score[0][1], ext_doc))\n",
    "\n",
    "    #     write out\n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name=model_name,\n",
    "            data=data,\n",
    "            out_f=f_out,\n",
    "\n",
    "            max_objects_per_query=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving using ltr\n",
      "elapsed time: 74.34756851196289\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "run_final_retrieval('retrievals/ltr1000')\n",
    "\n",
    "print ('elapsed time:',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_5                   \tall\t0.4800\r\n",
      "recall_1000           \tall\t0.9883\r\n",
      "ndcg_cut_10           \tall\t0.4660\r\n",
      "map_cut_1000          \tall\t0.3994\r\n"
     ]
    }
   ],
   "source": [
    "# trec_eval command for test of averaged vectors\n",
    "!trec_eval -m all_trec ./ap_88_89/qrel retrievals/ltr1000.run | grep -E \"^ndcg_cut_10\\s|^map_cut_1000\\s|^P_5\\s|^recall_1000\\s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task 4: Write a report [20 points; instant FAIL if not provided] ###\n",
    "\n",
    "The report should be a PDF file created using the [sigconf ACM template](https://www.acm.org/publications/proceedings-template) and will determine a significant part of your grade.\n",
    "\n",
    "   * It should explain what you have implemented, motivate your experiments and detail what you expect to learn from them. **[10 points]**\n",
    "   * Lastly, provide a convincing analysis of your results and conclude the report accordingly. **[10 points]**\n",
    "      * Do all methods perform similarly on all queries? Why?\n",
    "      * Is there a single retrieval model that outperforms all other retrieval models (i.e., silver bullet)?\n",
    "      * ...\n",
    "\n",
    "**Hand in the report and your self-contained implementation source files.** Only send us the files that matter, organized in a well-documented zip/tgz file with clear instructions on how to reproduce your results. That is, we want to be able to regenerate all your results with minimal effort. You can assume that the index and ground-truth information is present in the same file structure as the one we have provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
